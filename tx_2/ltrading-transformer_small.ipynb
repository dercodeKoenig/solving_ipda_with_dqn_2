{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c30e6f3-94f2-4fcf-9793-821d75d1f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd    \n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "name = \"dqn_trading_transformer_small\"\n",
    "resume = True\n",
    "#resume = False\n",
    "\n",
    "warmup_parallel = 4\n",
    "train_parallel = 4\n",
    "warmup_steps = 1000\n",
    "\n",
    "lr = 0.0001\n",
    "memory_size = 50000\n",
    "gamma = 0.95\n",
    "exploration = 0.02\n",
    "target_model_sync = 100\n",
    "batch_size = 32\n",
    "\n",
    "dlen = 120\n",
    "pos_size = 0.02 * 100000\n",
    "comm = 15/100000\n",
    "res_high = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa1857a-99cd-4633-a6fb-0616a475f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "    print(\"created ./logs\")\n",
    "\n",
    "def Load(file):\n",
    "    f = open(file, \"rb\")\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72913f11-cf58-41b8-bcf5-34293e18b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class candle_class:\n",
    "    def __init__(self, o,h,l,c,t):\n",
    "        self.o=o\n",
    "        self.h=h\n",
    "        self.l=l\n",
    "        self.c=c\n",
    "        self.t=t\n",
    "\n",
    "class environment:\n",
    "    def __init__(self):\n",
    "        self.data_dir = \"../archive\"\n",
    "        #print(self.files)\n",
    "        #self.reset()\n",
    "\n",
    "    def reset(self, first = False):\n",
    "        self.files = [self.data_dir+\"/\"+x for x in os.listdir(self.data_dir) if \"candle_classes\" in x]\n",
    "        p = random.choice(self.files)\n",
    "        print(\"using\",p)\n",
    "        self.candles = Load(p)\n",
    "        #print(self.candles)\n",
    "        \n",
    "        \n",
    "        self.current_index = 0\n",
    "        if first:\n",
    "            self.current_index = random.randint(0,len(self.candles)-50000)\n",
    "            \n",
    "        self.d1_candles = deque(maxlen = dlen)\n",
    "        self.h4_candles = deque(maxlen = dlen)\n",
    "        self.h1_candles = deque(maxlen = dlen)\n",
    "        self.m15_candles = deque(maxlen = dlen)\n",
    "        \n",
    "        self.position = 0\n",
    "        self.entry_price = 0\n",
    "        self.equity = 0\n",
    "        self.current_equity = 0\n",
    "        self.balance = 0\n",
    "        \n",
    "            \n",
    "        self.get_sample_candles()\n",
    "        return [self.scale_candles(self.m15_candles), self.scale_candles(self.h1_candles), self.scale_candles(self.h4_candles), self.scale_candles(self.d1_candles), self.position]\n",
    "            \n",
    "    def close(self):\n",
    "        if self.position !=0:\n",
    "            self.balance = self.equity\n",
    "            self.position = 0\n",
    "        \n",
    "    def step(self, action) :\n",
    "        last_equity = self.equity\n",
    "        reset_entry_price = False\n",
    "        if action == 1: # long\n",
    "            if self.position != 1:\n",
    "                self.close()\n",
    "                self.position = 1\n",
    "                self.balance -= pos_size * comm\n",
    "                reset_entry_price = True\n",
    "                \n",
    "        if action == 0: # short\n",
    "            if self.position != -1:\n",
    "                self.close()\n",
    "                self.position = -1\n",
    "                self.balance -= pos_size * comm\n",
    "                reset_entry_price = True\n",
    "        \n",
    "        \n",
    "        if self.get_sample_candles() == -1:\n",
    "            print(\"error\")\n",
    "            return -1\n",
    "            \n",
    "        current_close = self.m15_candles[-1].c\n",
    "        if reset_entry_price: self.entry_price = self.m15_candles[-1].o\n",
    "        \n",
    "        percent_change = (current_close - self.entry_price) / self.entry_price\n",
    "\n",
    "        self.equity = self.balance + percent_change * pos_size * self.position\n",
    "        \n",
    "        reward = self.equity - last_equity\n",
    "        next_observation = [self.scale_candles(self.m15_candles), self.scale_candles(self.h1_candles), self.scale_candles(self.h4_candles), self.scale_candles(self.d1_candles), self.position]\n",
    "            \n",
    "        return next_observation, reward, len(self.candles) == self.current_index\n",
    "        \n",
    "        \n",
    "    def get_sample_candles(self):\n",
    "        if len(self.candles) == self.current_index:\n",
    "            return -1\n",
    "        while True:\n",
    "            # return dlen candles of d1, h4, h1 and m15\n",
    "            current_candle = self.candles[self.current_index]\n",
    "            current_hour = int(current_candle.t.split(\":\")[0])\n",
    "            current_closing_minute = int(current_candle.t.split(\":\")[1])\n",
    "\n",
    "            # m15 candles:\n",
    "            open_minute = int(current_closing_minute / 15) * 15 # candle saved the last minute but opening minute is better to use\n",
    "            self.m15_candles.append(candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour) +\":\"+str(open_minute)))\n",
    "\n",
    "            # h1 candles:\n",
    "            if  open_minute == 0: # a new hour candle started\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h1_candles) > 0:\n",
    "                    self.h1_candles[-1].c = current_candle.c\n",
    "                    self.h1_candles[-1].h = max(current_candle.h, self.h1_candles[-1].h)\n",
    "                    self.h1_candles[-1].l = min(current_candle.l, self.h1_candles[-1].l)\n",
    "\n",
    "            # h4 candles:\n",
    "            # create a new h4 candle when hour is 17, 21, 1, 5, 9, 13\n",
    "            if  (current_hour == 17 or current_hour == 21 or current_hour == 1 or current_hour == 5 or current_hour == 9 or current_hour == 13) and open_minute == 0:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h4_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h4_candles) > 0:\n",
    "                    self.h4_candles[-1].c = current_candle.c\n",
    "                    self.h4_candles[-1].h = max(current_candle.h, self.h4_candles[-1].h)\n",
    "                    self.h4_candles[-1].l = min(current_candle.l, self.h4_candles[-1].l)\n",
    "\n",
    "            # d1 candles:\n",
    "            # create a new d1 candle when hour is 17\n",
    "            if  current_hour == 17 and open_minute == 0:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.d1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.d1_candles) > 0:\n",
    "                    self.d1_candles[-1].c = current_candle.c\n",
    "                    self.d1_candles[-1].h = max(current_candle.h, self.d1_candles[-1].h)\n",
    "                    self.d1_candles[-1].l = min(current_candle.l, self.d1_candles[-1].l)\n",
    "\n",
    "            self.current_index+=1    \n",
    "            if len(self.d1_candles) == dlen:\n",
    "                break\n",
    "\n",
    "        return self.m15_candles,  self.h1_candles, self.h4_candles, self.d1_candles\n",
    "    \n",
    "    \n",
    "    def scale_candles(self, candles):\n",
    "        def scale_p(p):\n",
    "            return int((p - max_l) / hlrange * (res_high))\n",
    "        max_h = 0\n",
    "        max_l = 1000000\n",
    "        for i in candles:\n",
    "            if i.h > max_h:\n",
    "                max_h = i.h\n",
    "            if i.l < max_l:\n",
    "                max_l = i.l\n",
    "        hlrange = max_h - max_l\n",
    "        \n",
    "        \n",
    "        def scale_time(t):\n",
    "            hour = int(t.split(\":\")[0])\n",
    "            minute = int(t.split(\":\")[1])\n",
    "            total = hour * 60 + minute\n",
    "            max_t = 24*60\n",
    "            scaled = total / max_t\n",
    "            return scaled\n",
    "            \n",
    "        \n",
    "        \n",
    "        image = []\n",
    "        for i in candles:\n",
    "            clm = np.zeros(shape = (res_high+1))\n",
    "            color = 1 if i.o<i.c else -1\n",
    "            high_scaled = scale_p(i.h)\n",
    "            low_scaled = scale_p(i.l)\n",
    "            clm[low_scaled:high_scaled] = 0.5 * color\n",
    "            open_scaled = scale_p(i.o)\n",
    "            close_scaled = scale_p(i.c)\n",
    "            if color == 1:\n",
    "                clm[open_scaled:close_scaled+1] = color\n",
    "            if color == -1:\n",
    "                clm[close_scaled:open_scaled+1] = color\n",
    "                \n",
    "            c_time = scale_time(i.t)\n",
    "            clm[-1] = c_time\n",
    "            image.append(clm)\n",
    "        \n",
    "        current_close = candles[-1].c\n",
    "        scaled_close = scale_p(current_close)\n",
    "        clm = np.zeros(shape = (res_high+1))\n",
    "        clm[scaled_close] = 1\n",
    "        image.append(clm)\n",
    "        \n",
    "        return np.array(image, dtype = \"float32\").T\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e45129f-c84c-4ca0-b6ea-94cbf198af0d",
   "metadata": {},
   "source": [
    "x = environment()\n",
    "m15,h1,h4,d1,pos = x.reset(True)\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(m15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46640191-4de7-4379-b28a-b26c1567736c",
   "metadata": {},
   "source": [
    "#x = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "x = tf.convert_to_tensor(np.array(m15).reshape(1,res_high+1, dlen+1))\n",
    "#x1 = image\n",
    "#x2 = time\n",
    "x1 = x[::, :-1, :-1]\n",
    "x2 = x[::,-1,:-1]\n",
    "current_pos = x[::,::, -1]\n",
    "print(x.shape)\n",
    "print(x1.shape)\n",
    "print(x2.shape)\n",
    "print(current_pos.shape)\n",
    "\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(x1.numpy()[0])\n",
    "plt.show()\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(x2.numpy())\n",
    "plt.show()\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(current_pos.numpy())\n",
    "plt.show()\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(x.numpy()[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d93b96-6791-4063-8051-069a9f830501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.05, **kwargs):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(TransformerBlock, self).get_config()\n",
    "        base_config['embed_dim'] = self.embed_dim\n",
    "        base_config['num_heads'] = self.num_heads\n",
    "        base_config['ff_dim'] = self.ff_dim\n",
    "        base_config['rate'] = self.rate\n",
    "        return base_config\n",
    "    \n",
    "    \n",
    "    \n",
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim, **kwargs):\n",
    "        self.maxlen = maxlen\n",
    "        self.embed_dim = embed_dim\n",
    "        super(PositionEmbedding, self).__init__(**kwargs)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = self.maxlen\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(PositionEmbedding, self).get_config()\n",
    "        base_config['maxlen'] = self.maxlen\n",
    "        base_config['embed_dim'] = self.embed_dim\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b701228a-b593-43e5-a4fa-ddf2063b9579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 100, 121)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 100, 121)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_4 (Sli (None, 100, 121)     0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_6 (Sli (None, 100, 121)     0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 100, 121, 1)  0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 100, 121, 1)  0           tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 100, 121, 1)  0           tf.__operators__.getitem_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 100, 121, 1)  0           tf.__operators__.getitem_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 100, 121, 64) 5248        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 100, 121, 64) 5248        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 100, 121, 64) 5248        reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 100, 121, 64) 5248        reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 100, 121, 65) 0           reshape[0][0]                    \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100, 121, 65) 0           reshape_3[0][0]                  \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 100, 121, 65) 0           reshape_6[0][0]                  \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 100, 121, 65) 0           reshape_9[0][0]                  \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100, 121, 64) 4224        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 100, 121, 64) 4224        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 100, 121, 64) 4224        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 100, 121, 64) 4224        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (None, 121, 100, 64) 0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 121)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_1 (TFOpL (None, 121, 100, 64) 0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (None, 121)          0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_2 (TFOpL (None, 121, 100, 64) 0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_5 (Sli (None, 121)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_3 (TFOpL (None, 121, 100, 64) 0           dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_7 (Sli (None, 121)          0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 121, 6400)    0           tf.compat.v1.transpose[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 121, 1)       0           tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 121, 6400)    0           tf.compat.v1.transpose_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 121, 1)       0           tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 121, 6400)    0           tf.compat.v1.transpose_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 121, 1)       0           tf.__operators__.getitem_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 121, 6400)    0           tf.compat.v1.transpose_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 121, 1)       0           tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 121, 6401)    0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 121, 6401)    0           reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 121, 6401)    0           reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 121, 6401)    0           reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 121, 512)     3277824     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 121, 512)     3277824     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 121, 512)     3277824     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 121, 512)     3277824     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 121, 512)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 121, 512)     0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 121, 512)     0           dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 121, 512)     0           dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 121, 512)     262656      leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 121, 512)     262656      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 121, 512)     262656      leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 121, 512)     262656      leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 121, 512)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 121, 512)     0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 121, 512)     0           dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 121, 512)     0           dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 121, 96)      49248       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 121, 96)      49248       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 121, 96)      49248       leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 121, 96)      49248       leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 121, 96)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 121, 96)      0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 121, 96)      0           dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 121, 96)      0           dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 121, 96)      192         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 121, 96)      192         leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, 121, 96)      192         leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_21 (LayerNo (None, 121, 96)      192         leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding (PositionEmb (None, 121, 96)      11616       layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding_1 (PositionE (None, 121, 96)      11616       layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding_2 (PositionE (None, 121, 96)      11616       layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding_3 (PositionE (None, 121, 96)      11616       layer_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block (TransformerB (None, 121, 96)      347200      position_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_3 (Transforme (None, 121, 96)      347200      position_embedding_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_6 (Transforme (None, 121, 96)      347200      position_embedding_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_9 (Transforme (None, 121, 96)      347200      position_embedding_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_1 (Transforme (None, 121, 96)      347200      transformer_block[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_4 (Transforme (None, 121, 96)      347200      transformer_block_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_7 (Transforme (None, 121, 96)      347200      transformer_block_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_10 (Transform (None, 121, 96)      347200      transformer_block_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_2 (Transforme (None, 121, 96)      347200      transformer_block_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_5 (Transforme (None, 121, 96)      347200      transformer_block_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_8 (Transforme (None, 121, 96)      347200      transformer_block_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_11 (Transform (None, 121, 96)      347200      transformer_block_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 121, 512)     49664       transformer_block_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 121, 512)     49664       transformer_block_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 121, 512)     49664       transformer_block_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 121, 512)     49664       transformer_block_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 121, 512)     0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 121, 512)     0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 121, 512)     0           dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 121, 512)     0           dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 121, 512)     262656      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 121, 512)     262656      leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 121, 512)     262656      leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 121, 512)     262656      leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 121, 512)     0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 121, 512)     0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 121, 512)     0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 121, 512)     0           dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 256)          591360      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 256)          591360      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 256)          591360      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 256)          591360      leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         263168      gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1024)         263168      gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 1024)         263168      gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 1024)         263168      gru_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 1024)         0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 1024)         0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 1024)         0           dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 1024)         0           dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1024)         1049600     leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 1024)         1049600     leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 1024)         1049600     leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 1024)         1049600     leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 1024)         0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 1024)         0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 1024)         0           dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 1024)         0           dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1024)         1049600     leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1024)         1049600     leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 1024)         1049600     leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 1024)         1049600     leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 1024)         0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 1024)         0           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 1024)         0           dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 1024)         0           dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 256)          262400      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 256)          262400      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 256)          262400      leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 256)          262400      leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 256)          0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 256)          0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 256)          0           dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1025)         0           leaky_re_lu_8[0][0]              \n",
      "                                                                 leaky_re_lu_17[0][0]             \n",
      "                                                                 leaky_re_lu_26[0][0]             \n",
      "                                                                 leaky_re_lu_35[0][0]             \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 1024)         1050624     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 1024)         0           dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 1024)         1049600     leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 1024)         0           dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 1024)         1049600     leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 1024)         0           dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 2)            2048        leaky_re_lu_38[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 35,876,096\n",
      "Trainable params: 35,876,096\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def proc_chart(x):\n",
    "    #x1 = image\n",
    "    #x2 = time\n",
    "    x1 = x[::, :-1, :]\n",
    "    x2 = x[::,-1,:]\n",
    "\n",
    "    x1 = tf.keras.layers.Reshape((res_high, dlen+1, 1))(x1)\n",
    "    \n",
    "    x5 = tf.keras.layers.Conv2D(64, 9,activation=\"relu\", padding=\"same\")(x1)\n",
    "    x1 = tf.keras.layers.Concatenate()([x1,x5])\n",
    "    x1 = tf.keras.layers.Dense(64)(x1)\n",
    "    \n",
    "    x1 = tf.transpose(x1,perm=[0, 2, 1, 3])\n",
    "    x1 = tf.keras.layers.Reshape((dlen+1, res_high*x1.shape[-1]))(x1)\n",
    "    x2 = tf.keras.layers.Reshape((dlen+1, 1))(x2)\n",
    "    x1 = tf.keras.layers.Concatenate()([x1,x2])\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(512)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(512)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(96)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    \n",
    "    \n",
    "    x1 = PositionEmbedding(dlen+1, x1.shape[-1])(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "\n",
    "    x1 = tf.keras.layers.Dense(512)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(512)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    #x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x1 = tf.keras.layers.GRU(256)(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(256,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    #x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    return x1\n",
    "    \n",
    "if True:\n",
    "    input_m15 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h4 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_d1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    \n",
    "    x1 = proc_chart(input_m15)\n",
    "    x2 = proc_chart(input_h1)\n",
    "    x3 = proc_chart(input_h4)\n",
    "    x4 = proc_chart(input_d1)\n",
    "    \n",
    "    input_net_position = tf.keras.layers.Input(shape = (1))\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Concatenate()([x1,x2,x3,x4,input_net_position])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(2, activation = \"linear\", use_bias=False, dtype=\"float32\")(x)\n",
    "    model = tf.keras.Model([input_m15,input_h1,input_h4, input_d1, input_net_position], outputs)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4835645d-95a9-484d-b4d3-04ce14fb2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#states = m15candles, h1candles, h4candles, d1candles, position\n",
    "#states =(5,dlen), (5,dlen), (5,dlen), (5,dlen), (1)\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, model,\n",
    "                 n_actions,\n",
    "                 memory_size = 100000, \n",
    "                 optimizer = tf.keras.optimizers.Adam(0.0005), \n",
    "                 gamma = 0.99,\n",
    "                 batch_size =32,\n",
    "                 name = \"dqn1\",\n",
    "                 target_model_sync = 1000,\n",
    "                 exploration = 0.01\n",
    "                ):\n",
    "        self.exploration = exploration\n",
    "        self.gamma = gamma\n",
    "        self.n_actions = n_actions\n",
    "        self.batch_size = batch_size\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.memory_size = memory_size\n",
    "        self.optimizer = optimizer\n",
    "        self.m1 = np.eye(self.n_actions, dtype=\"float32\")\n",
    "        self.target_model = tf.keras.models.clone_model(self.model)\n",
    "        self.target_model_sync = target_model_sync\n",
    "   \n",
    "        self.memory = deque(maxlen = self.memory_size)\n",
    "      \n",
    "    \n",
    "    def copy_weights(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "      \n",
    "    def load_weights(self):\n",
    "        self.model.load_weights(self.name)\n",
    "    def save_weights(self):\n",
    "        self.model.save_weights(self.name, overwrite = True)\n",
    "        \n",
    "    @tf.function(jit_compile = False)\n",
    "    def model_call(self, x):\n",
    "        x1, x2, x3, x4, x5 = x\n",
    "        return tf.math.argmax(self.model([x1,x2,x3,x4,x5]), axis = 1)\n",
    "    \n",
    "    def select_actions(self, state1, state2, state3, state4, state5):\n",
    "        if np.random.random() < self.exploration: # random action\n",
    "            return [np.random.randint(0,self.n_actions) for _ in range(len(state5))]\n",
    "        \n",
    "        ret = self.model_call([state1, state2, state3, state4, state5])\n",
    "        return ret.numpy()\n",
    "\n",
    "\n",
    "        \n",
    "    def observe_sasrt(self, state, action, next_state, reward, terminal):\n",
    "        self.memory.append([state, action, reward, 1-int(terminal), next_state])\n",
    "        \n",
    "    @tf.function(jit_compile = False)\n",
    "    def get_target_q(self, next_states, rewards, terminals):\n",
    "        estimated_q_values_next = self.target_model(next_states)\n",
    "        q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
    "        target_q_values = q_batch * self.gamma * terminals + rewards\n",
    "        return target_q_values\n",
    "\n",
    "        \n",
    "    #@tf.function(jit_compile = True)\n",
    "    @tf.function(jit_compile = False) # not working for lstm\n",
    "    def tstep(self, data):\n",
    "        states, next_states, rewards, terminals, masks = data\n",
    "        target_q_values = self.get_target_q(next_states, rewards, terminals)\n",
    "        \n",
    "        with tf.GradientTape() as t:\n",
    "            model_return = self.model(states, training=True) \n",
    "            mask_return = model_return * masks\n",
    "            estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
    "            #print(estimated_q_values, mask_return, model_return, masks)\n",
    "            loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
    "            loss = tf.reduce_mean(loss_e)\n",
    "        \n",
    "        \n",
    "        gradient = t.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradient, self.model.trainable_variables))\n",
    "        \n",
    "        return loss, tf.reduce_mean(estimated_q_values)\n",
    "    \n",
    "    \n",
    "    def data_get_func(self):\n",
    "        idx = np.random.randint(0, len(self.memory), self.batch_size)\n",
    "        sarts_batch = [self.memory[i] for i in idx]\n",
    "        \n",
    "        states = [x[0] for x in sarts_batch]\n",
    "        states_1 = np.array([x[0] for x in states], dtype=\"float32\")\n",
    "        states_2 = np.array([x[1] for x in states], dtype=\"float32\")\n",
    "        states_3 = np.array([x[2] for x in states], dtype=\"float32\")\n",
    "        states_4 = np.array([x[3] for x in states], dtype=\"float32\")\n",
    "        states_5 = np.array([x[4] for x in states], dtype=\"float32\")\n",
    "        \n",
    "        actions = [x[1] for x in sarts_batch]\n",
    "        rewards = np.array([x[2] for x in sarts_batch], dtype=\"float32\")\n",
    "        terminals = np.array([x[3] for x in sarts_batch], dtype=\"float32\")\n",
    "        \n",
    "        next_states = [x[4] for x in sarts_batch]\n",
    "        next_states_1 = np.array([x[0] for x in next_states], dtype=\"float32\")\n",
    "        next_states_2 = np.array([x[1] for x in next_states], dtype=\"float32\")\n",
    "        next_states_3 = np.array([x[2] for x in next_states], dtype=\"float32\")\n",
    "        next_states_4 = np.array([x[3] for x in next_states], dtype=\"float32\")\n",
    "        next_states_5 = np.array([x[4] for x in next_states], dtype=\"float32\")\n",
    "        #print(actions)\n",
    "        masks = np.array(self.m1[actions])\n",
    "        return [states_1, states_2, states_3, states_4, states_5], [next_states_1, next_states_2, next_states_3, next_states_4, next_states_5], rewards, terminals, masks\n",
    "\n",
    "    def update_parameters(self):\n",
    "        self.total_steps_trained+=1\n",
    "        if self.total_steps_trained % self.target_model_sync == 0:\n",
    "            self.copy_weights()\n",
    "\n",
    "        t0 = time.time()\n",
    "        data = self.data_get_func()\n",
    "        t1 = time.time()\n",
    "        result= self.tstep(data)\n",
    "        t2 = time.time()\n",
    "   \n",
    "        return  result[0], result[1], t2-t1,t1-t0\n",
    "    \n",
    "    def train(self, num_steps, envs, log_interval = 1000, warmup = 0):\n",
    "        self.total_steps_trained = -1\n",
    "\n",
    "        num_envs = len(envs)\n",
    "        states = [x.reset(True) for x in envs]\n",
    "        \n",
    "        current_episode_reward_sum = 0\n",
    "        times= deque(maxlen=10)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.longs = 0\n",
    "        self.shorts = 0\n",
    "\n",
    "        self.total_rewards = []\n",
    "        self.losses = [0]\n",
    "        self.q_v = [0]\n",
    "        \n",
    "        def save_current_run():\n",
    "            self.save_weights()\n",
    "            file = open(log_folder+\"logs/loss_log.txt\", \"a\")  \n",
    "            #for loss in self.losses:\n",
    "                        #file.write(str(loss))\n",
    "                        #file.write(\"\\n\")\n",
    "            file.write(str(np.mean(self.losses)))\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "\n",
    "            file = open(log_folder+\"logs/qv_log.txt\", \"a\")  \n",
    "            #for qv in self.q_v:\n",
    "                        #file.write(str(qv))\n",
    "                        #file.write(\"\\n\")\n",
    "            file.write(str(np.mean(self.q_v)))\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "\n",
    "            file = open(log_folder+\"logs/rewards_log.txt\", \"a\")  \n",
    "            #for total_reward in self.total_rewards:\n",
    "                        #file.write(str(total_reward))\n",
    "                        #file.write(\"\\n\")\n",
    "                    \n",
    "            file.write(str(np.mean(self.total_rewards)))\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "            \n",
    "    \n",
    "\n",
    "            self.total_rewards = []\n",
    "            self.losses = [0]\n",
    "            self.q_v = [0]\n",
    "        \n",
    "        try:\n",
    "            for i in range(num_steps):\n",
    "                if i % log_interval == 0:\n",
    "                    progbar = tf.keras.utils.Progbar(log_interval, interval=0.1, stateful_metrics = [\"reward sum\", \"t\", \"l/s\"])\n",
    "                    self.longs = 0\n",
    "                    self.shorts = 0\n",
    "\n",
    "                t4 = time.time()\n",
    "                states_1 = np.array([x[0] for x in states], dtype = \"float32\")\n",
    "                states_2 = np.array([x[1] for x in states], dtype = \"float32\")\n",
    "                states_3 = np.array([x[2] for x in states], dtype = \"float32\")\n",
    "                states_4 = np.array([x[3] for x in states], dtype = \"float32\")\n",
    "                states_5 = np.array([x[4] for x in states], dtype = \"float32\")\n",
    "                \n",
    "                actions = self.select_actions(states_1, states_2, states_3, states_4, states_5)\n",
    "                for action in actions:\n",
    "                    if action == 0:\n",
    "                        self.shorts+=1\n",
    "                    elif action == 1:\n",
    "                        self.longs+=1\n",
    "\n",
    "                sasrt_pairs = []\n",
    "                for index in range(num_envs):\n",
    "                    sasrt_pairs.append([states[index], actions[index]]+[x for x in envs[index].step(actions[index])])\n",
    "\n",
    "                next_states = [x[2] for x in sasrt_pairs]\n",
    "\n",
    "                reward = [x[3] for x in sasrt_pairs]\n",
    "                current_episode_reward_sum += np.sum(reward)\n",
    "\n",
    "                self.total_rewards.extend(reward)\n",
    "                for index, o in enumerate(sasrt_pairs):\n",
    "                    #print(o)\n",
    "                    if o[4] == True:\n",
    "                        next_states[index] = envs[index].reset()\n",
    "                    self.observe_sasrt(o[0], o[1], o[2], o[3], o[4])\n",
    "\n",
    "                states = next_states\n",
    "                t5= time.time()\n",
    "                \n",
    "                td = 0\n",
    "                tt = 0\n",
    "                if i > warmup:\n",
    "                        loss, q, td, tt = self.update_parameters()\n",
    "                        self.losses.append(loss.numpy())\n",
    "                        self.q_v.append(q.numpy())\n",
    "                else:\n",
    "                    loss, q = 0, 0\n",
    "\n",
    "                end_time = time.time()\n",
    "                elapsed = (end_time - start_time) * 1000\n",
    "                times.append(elapsed)\n",
    "                start_time = end_time\n",
    "\n",
    "\n",
    "                if (i+1) % log_interval == 0:\n",
    "                    #print(\"-----------\")\n",
    "                    #print(\"l:\", np.mean(self.losses))\n",
    "                    #print(\"q:\", np.mean(self.q_v))\n",
    "                    #print(\"reward sum\", current_episode_reward_sum)\n",
    "                    #print(\"l/s\", (self.longs - self.shorts) / (1+self.longs+self.shorts))\n",
    "                    #print(\"t\", np.mean(times))\n",
    "                    #print(\"-----------\")\n",
    "                    save_current_run()\n",
    "\n",
    "                progbar.update(i%log_interval+1, values = \n",
    "                               [(\"loss\", np.mean(self.losses[-1:])),\n",
    "                                (\"mean q\", np.mean(self.q_v[-1:])),\n",
    "                                (\"rewards\", np.mean(reward)),\n",
    "                                (\"reward sum\", current_episode_reward_sum),\n",
    "                                (\"l/s\", (self.longs - self.shorts) / (1+self.longs+self.shorts)),\n",
    "                                (\"t\", np.mean(times)),\n",
    "                               (\"td\", td),\n",
    "                               (\"tt\", tt),\n",
    "                               (\"tv\", t5-t4)])\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nbreak!\")\n",
    "        \n",
    "        save_current_run()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4db0d3e-7df8-4a56-b06c-ea9aeb7a1783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights...\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "\n",
    "log_folder = \"./\"\n",
    "\n",
    "agent = DQNAgent(\n",
    "    model = model, \n",
    "    n_actions = 2, \n",
    "    memory_size = memory_size, \n",
    "    gamma=gamma,\n",
    "    optimizer = opt,\n",
    "    batch_size = batch_size, \n",
    "    target_model_sync = target_model_sync,\n",
    "    exploration = exploration,\n",
    "    name=log_folder+name+\".h5\")\n",
    "\n",
    "if resume:\n",
    "\tprint(\"loading weights...\")\n",
    "\tagent.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "411125ec-439f-4de3-bcc3-4e0abf9d3304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup...\n",
      "using ../archive/15_USDJPY.csv_candle_classes\n",
      "using ../archive/15_USDCHF.csv_candle_classes\n",
      "using ../archive/15_USDJPY.csv_candle_classes\n",
      "using ../archive/15_USDCHF.csv_candle_classes\n",
      " 248/1000 [======>.......................] - ETA: 44s - loss: 0.0000e+00 - mean q: 0.0000e+00 - rewards: -0.0184 - reward sum: -18.2609 - l/s: 0.9708 - t: 63.1629 - td: 0.0000e+00 - tt: 0.0000e+00 - tv: 0.0677\n",
      "\n",
      "break!\n"
     ]
    }
   ],
   "source": [
    "x = [environment() for _ in range(warmup_parallel)]\n",
    "print(\"warmup...\")\n",
    "n = warmup_steps\n",
    "agent.train(num_steps = n, envs = x, warmup = n, log_interval = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abb27070-100e-4c75-b51d-3d30d7132ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a81a7b-54d5-4796-b801-0e98ffee8890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "using ../archive/15_EURUSD.csv_candle_classes\n",
      "using ../archive/15_USDCAD.csv_candle_classes\n",
      "using ../archive/15_AUDUSD.csv_candle_classes\n",
      "using ../archive/15_USDJPY.csv_candle_classes\n",
      "1000/1000 [==============================] - 721s 722ms/step - loss: 0.7192 - mean q: 0.9727 - rewards: -0.0469 - reward sum: -187.7445 - l/s: -0.0185 - t: 710.4563 - td: 0.4491 - tt: 0.0060 - tv: 0.0629\n",
      "1000/1000 [==============================] - 727s 727ms/step - loss: 0.7289 - mean q: 0.7670 - rewards: -0.0275 - reward sum: -297.6567 - l/s: 0.1640 - t: 703.8505 - td: 0.4456 - tt: 0.0064 - tv: 0.0674\n",
      "1000/1000 [==============================] - 709s 709ms/step - loss: 0.7495 - mean q: 0.8038 - rewards: -0.0299 - reward sum: -417.4562 - l/s: 0.0130 - t: 707.5686 - td: 0.4365 - tt: 0.0061 - tv: 0.0656\n",
      "1000/1000 [==============================] - 734s 734ms/step - loss: 0.8413 - mean q: 0.9929 - rewards: -0.0423 - reward sum: -586.7832 - l/s: -0.0610 - t: 717.3676 - td: 0.4474 - tt: 0.0066 - tv: 0.0711\n",
      "1000/1000 [==============================] - 744s 744ms/step - loss: 0.7627 - mean q: 1.0624 - rewards: -0.0511 - reward sum: -791.2330 - l/s: 0.1255 - t: 720.8141 - td: 0.4508 - tt: 0.0066 - tv: 0.0731\n",
      "1000/1000 [==============================] - 766s 766ms/step - loss: 0.8326 - mean q: 0.7245 - rewards: -0.0027 - reward sum: -802.0248 - l/s: -0.0190 - t: 745.4445 - td: 0.4589 - tt: 0.0069 - tv: 0.0799\n",
      "1000/1000 [==============================] - 771s 771ms/step - loss: 0.7767 - mean q: -0.0530 - rewards: -0.0330 - reward sum: -934.0354 - l/s: 0.3214 - t: 782.7880 - td: 0.4595 - tt: 0.0069 - tv: 0.0824\n",
      "1000/1000 [==============================] - 774s 774ms/step - loss: 0.7626 - mean q: 0.2310 - rewards: -0.0256 - reward sum: -1036.3693 - l/s: 0.0795 - t: 761.2833 - td: 0.4598 - tt: 0.0070 - tv: 0.0885\n",
      "1000/1000 [==============================] - 782s 782ms/step - loss: 0.8344 - mean q: 0.6225 - rewards: -0.0363 - reward sum: -1181.5047 - l/s: 0.3069 - t: 765.3325 - td: 0.4586 - tt: 0.0068 - tv: 0.0981\n",
      "1000/1000 [==============================] - 786s 786ms/step - loss: 0.8064 - mean q: 0.4918 - rewards: -0.0069 - reward sum: -1209.0850 - l/s: 0.5604 - t: 808.0967 - td: 0.4614 - tt: 0.0067 - tv: 0.0991\n",
      "1000/1000 [==============================] - 799s 799ms/step - loss: 0.8597 - mean q: 0.2616 - rewards: 0.0108 - reward sum: -1166.0785 - l/s: 0.1560 - t: 787.6754 - td: 0.4637 - tt: 0.0069 - tv: 0.1035\n",
      "1000/1000 [==============================] - 811s 812ms/step - loss: 0.7795 - mean q: 0.3044 - rewards: -0.0294 - reward sum: -1283.6705 - l/s: 0.1280 - t: 790.8177 - td: 0.4673 - tt: 0.0073 - tv: 0.1121\n",
      "1000/1000 [==============================] - 888s 888ms/step - loss: 0.8002 - mean q: 0.0844 - rewards: -0.0302 - reward sum: -1404.5285 - l/s: 0.0575 - t: 913.1971 - td: 0.5071 - tt: 0.0074 - tv: 0.1126\n",
      "1000/1000 [==============================] - 856s 856ms/step - loss: 0.8846 - mean q: -0.0262 - rewards: -0.0183 - reward sum: -1477.6326 - l/s: 0.1335 - t: 727.1822 - td: 0.4901 - tt: 0.0075 - tv: 0.1160\n",
      "1000/1000 [==============================] - 761s 761ms/step - loss: 0.7435 - mean q: -0.2177 - rewards: -0.0139 - reward sum: -1533.3487 - l/s: 0.0855 - t: 797.8074 - td: 0.4486 - tt: 0.0069 - tv: 0.0999\n",
      "1000/1000 [==============================] - 764s 764ms/step - loss: 0.8140 - mean q: -0.2773 - rewards: -0.0083 - reward sum: -1566.6603 - l/s: -0.5659 - t: 789.8834 - td: 0.4482 - tt: 0.0069 - tv: 0.0996\n",
      "1000/1000 [==============================] - 758s 758ms/step - loss: 0.8087 - mean q: 0.0665 - rewards: -0.0258 - reward sum: -1669.7985 - l/s: -0.4809 - t: 725.7607 - td: 0.4461 - tt: 0.0068 - tv: 0.1009\n",
      "1000/1000 [==============================] - 757s 757ms/step - loss: 0.7994 - mean q: 0.5664 - rewards: -0.0169 - reward sum: -1737.2127 - l/s: -0.2179 - t: 723.7748 - td: 0.4461 - tt: 0.0068 - tv: 0.0982\n",
      " 171/1000 [====>.........................] - ETA: 10:31 - loss: 0.7572 - mean q: 0.9028 - rewards: -9.8011e-04 - reward sum: -1737.8831 - l/s: -0.1139 - t: 773.2991 - td: 0.4491 - tt: 0.0068 - tv: 0.0988"
     ]
    }
   ],
   "source": [
    "x = [environment() for _ in range(train_parallel)]\n",
    "print(\"training...\")\n",
    "n = 1000000000\n",
    "agent.train(num_steps = n, envs = x, warmup = 0, log_interval = 1000)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99668af5-9022-416d-9a39-46886ff14463",
   "metadata": {},
   "outputs": [],
   "source": [
    "rew = [i[2] for i in agent.memory]\n",
    "sorted(rew)[0:10], sorted(rew)[-10:][::-1], \" - \", np.mean([abs(i) for i in rew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a23302-fdb4-45f5-a315-6cc784c94461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ba604-8d37-4c7c-957c-74e333f91a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8225cbed-9425-4cf1-af1b-9b23242d418f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357d921-1a96-4ba9-b6d5-5d149087d4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a621bf-700d-40a8-834a-2f19bc1d836f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "autoscrollcelloutput": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
