{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30e6f3-94f2-4fcf-9793-821d75d1f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd    \n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "name = \"dqn_trading_transformer_small\"\n",
    "resume = True\n",
    "#resume = False\n",
    "\n",
    "warmup_parallel = 4\n",
    "train_parallel = 4\n",
    "warmup_steps = 1000\n",
    "\n",
    "lr = 0.0005\n",
    "memory_size = 32000\n",
    "gamma = 0.975\n",
    "exploration = 0.02\n",
    "target_model_sync = 5000\n",
    "batch_size = 64\n",
    "\n",
    "dlen = 120\n",
    "pos_size = 0.02 * 100000\n",
    "comm = 15/100000\n",
    "res_high = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa1857a-99cd-4633-a6fb-0616a475f9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created ./logs\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "    print(\"created ./logs\")\n",
    "\n",
    "def Load(file):\n",
    "    f = open(file, \"rb\")\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72913f11-cf58-41b8-bcf5-34293e18b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class candle_class:\n",
    "    def __init__(self, o,h,l,c,t):\n",
    "        self.o=o\n",
    "        self.h=h\n",
    "        self.l=l\n",
    "        self.c=c\n",
    "        self.t=t\n",
    "\n",
    "class environment:\n",
    "    def __init__(self):\n",
    "        self.data_dir = \"./archive\"\n",
    "        #print(self.files)\n",
    "        #self.reset()\n",
    "\n",
    "    def reset(self, first = False):\n",
    "        self.files = [self.data_dir+\"/\"+x for x in os.listdir(self.data_dir) if \"candle_classes\" in x]\n",
    "        p = random.choice(self.files)\n",
    "        print(\"using\",p)\n",
    "        self.candles = Load(p)\n",
    "        #print(self.candles)\n",
    "        \n",
    "        \n",
    "        self.current_index = 0\n",
    "        if first:\n",
    "            self.current_index = random.randint(0,len(self.candles)-50000)\n",
    "            \n",
    "        self.d1_candles = deque(maxlen = dlen)\n",
    "        self.h4_candles = deque(maxlen = dlen)\n",
    "        self.h1_candles = deque(maxlen = dlen)\n",
    "        self.m15_candles = deque(maxlen = dlen)\n",
    "        \n",
    "        self.position = 0\n",
    "        self.entry_price = 0\n",
    "        self.equity = 0\n",
    "        self.current_equity = 0\n",
    "        self.balance = 0\n",
    "        \n",
    "            \n",
    "        self.get_sample_candles()\n",
    "        return [self.scale_candles(self.m15_candles), self.scale_candles(self.h1_candles), self.scale_candles(self.h4_candles), self.scale_candles(self.d1_candles), self.position]\n",
    "            \n",
    "    def close(self):\n",
    "        if self.position !=0:\n",
    "            self.balance = self.equity\n",
    "            self.position = 0\n",
    "        \n",
    "    def step(self, action) :\n",
    "        last_equity = self.equity\n",
    "        reset_entry_price = False\n",
    "        if action == 1: # long\n",
    "            if self.position != 1:\n",
    "                self.close()\n",
    "                self.position = 1\n",
    "                self.balance -= pos_size * comm\n",
    "                reset_entry_price = True\n",
    "                \n",
    "        if action == 0: # short\n",
    "            if self.position != -1:\n",
    "                self.close()\n",
    "                self.position = -1\n",
    "                self.balance -= pos_size * comm\n",
    "                reset_entry_price = True\n",
    "        \n",
    "        \n",
    "        if self.get_sample_candles() == -1:\n",
    "            print(\"error\")\n",
    "            return -1\n",
    "            \n",
    "        current_close = self.m15_candles[-1].c\n",
    "        if reset_entry_price: self.entry_price = self.m15_candles[-1].o\n",
    "        \n",
    "        percent_change = (current_close - self.entry_price) / self.entry_price\n",
    "\n",
    "        self.equity = self.balance + percent_change * pos_size * self.position\n",
    "        \n",
    "        reward = self.equity - last_equity\n",
    "        next_observation = [self.scale_candles(self.m15_candles), self.scale_candles(self.h1_candles), self.scale_candles(self.h4_candles), self.scale_candles(self.d1_candles), self.position]\n",
    "            \n",
    "        return next_observation, reward, len(self.candles) == self.current_index\n",
    "        \n",
    "        \n",
    "    def get_sample_candles(self):\n",
    "        if len(self.candles) == self.current_index:\n",
    "            return -1\n",
    "        while True:\n",
    "            # return dlen candles of d1, h4, h1 and m15\n",
    "            current_candle = self.candles[self.current_index]\n",
    "            current_hour = int(current_candle.t.split(\":\")[0])\n",
    "            current_closing_minute = int(current_candle.t.split(\":\")[1])\n",
    "\n",
    "            # m15 candles:\n",
    "            open_minute = int(current_closing_minute / 15) * 15 # candle saved the last minute but opening minute is better to use\n",
    "            self.m15_candles.append(candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour) +\":\"+str(open_minute)))\n",
    "\n",
    "            # h1 candles:\n",
    "            if  open_minute == 0: # a new hour candle started\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h1_candles) > 0:\n",
    "                    self.h1_candles[-1].c = current_candle.c\n",
    "                    self.h1_candles[-1].h = max(current_candle.h, self.h1_candles[-1].h)\n",
    "                    self.h1_candles[-1].l = min(current_candle.l, self.h1_candles[-1].l)\n",
    "\n",
    "            # h4 candles:\n",
    "            # create a new h4 candle when hour is 17, 21, 1, 5, 9, 13\n",
    "            if  (current_hour == 17 or current_hour == 21 or current_hour == 1 or current_hour == 5 or current_hour == 9 or current_hour == 13) and open_minute == 0:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h4_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h4_candles) > 0:\n",
    "                    self.h4_candles[-1].c = current_candle.c\n",
    "                    self.h4_candles[-1].h = max(current_candle.h, self.h4_candles[-1].h)\n",
    "                    self.h4_candles[-1].l = min(current_candle.l, self.h4_candles[-1].l)\n",
    "\n",
    "            # d1 candles:\n",
    "            # create a new d1 candle when hour is 17\n",
    "            if  current_hour == 17 and open_minute == 0:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.d1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.d1_candles) > 0:\n",
    "                    self.d1_candles[-1].c = current_candle.c\n",
    "                    self.d1_candles[-1].h = max(current_candle.h, self.d1_candles[-1].h)\n",
    "                    self.d1_candles[-1].l = min(current_candle.l, self.d1_candles[-1].l)\n",
    "\n",
    "            self.current_index+=1    \n",
    "            if len(self.d1_candles) == dlen:\n",
    "                break\n",
    "\n",
    "        return self.m15_candles,  self.h1_candles, self.h4_candles, self.d1_candles\n",
    "    \n",
    "    \n",
    "    def scale_candles(self, candles):\n",
    "        def scale_p(p):\n",
    "            return int((p - max_l) / hlrange * (res_high))\n",
    "        max_h = 0\n",
    "        max_l = 1000000\n",
    "        for i in candles:\n",
    "            if i.h > max_h:\n",
    "                max_h = i.h\n",
    "            if i.l < max_l:\n",
    "                max_l = i.l\n",
    "        hlrange = max_h - max_l\n",
    "        \n",
    "        \n",
    "        def scale_time(t):\n",
    "            hour = int(t.split(\":\")[0])\n",
    "            minute = int(t.split(\":\")[1])\n",
    "            total = hour * 60 + minute\n",
    "            max_t = 24*60\n",
    "            scaled = total / max_t\n",
    "            return scaled\n",
    "            \n",
    "        \n",
    "        \n",
    "        image = []\n",
    "        for i in candles:\n",
    "            clm = np.zeros(shape = (res_high+1))\n",
    "            color = 1 if i.o<i.c else -1\n",
    "            high_scaled = scale_p(i.h)\n",
    "            low_scaled = scale_p(i.l)\n",
    "            clm[low_scaled:high_scaled] = 0.5 * color\n",
    "            open_scaled = scale_p(i.o)\n",
    "            close_scaled = scale_p(i.c)\n",
    "            if color == 1:\n",
    "                clm[open_scaled:close_scaled+1] = color\n",
    "            if color == -1:\n",
    "                clm[close_scaled:open_scaled+1] = color\n",
    "                \n",
    "            c_time = scale_time(i.t)\n",
    "            clm[-1] = c_time\n",
    "            image.append(clm)\n",
    "        \n",
    "        current_close = candles[-1].c\n",
    "        scaled_close = scale_p(current_close)\n",
    "        clm = np.zeros(shape = (res_high+1))\n",
    "        clm[scaled_close] = 1\n",
    "        image.append(clm)\n",
    "        \n",
    "        return np.array(image).T\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e45129f-c84c-4ca0-b6ea-94cbf198af0d",
   "metadata": {},
   "source": [
    "x = environment()\n",
    "m15,h1,h4,d1,pos = x.reset(True)\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(m15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46640191-4de7-4379-b28a-b26c1567736c",
   "metadata": {},
   "source": [
    "#x = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "x = tf.convert_to_tensor(np.array(m15).reshape(1,res_high+1, dlen+1))\n",
    "#x1 = image\n",
    "#x2 = time\n",
    "x1 = x[::, :-1, :-1]\n",
    "x2 = x[::,-1,:-1]\n",
    "current_pos = x[::,::, -1]\n",
    "print(x.shape)\n",
    "print(x1.shape)\n",
    "print(x2.shape)\n",
    "print(current_pos.shape)\n",
    "\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(x1.numpy()[0])\n",
    "plt.show()\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(x2.numpy())\n",
    "plt.show()\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(current_pos.numpy())\n",
    "plt.show()\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(x.numpy()[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d93b96-6791-4063-8051-069a9f830501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.05, **kwargs):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(TransformerBlock, self).get_config()\n",
    "        base_config['embed_dim'] = self.embed_dim\n",
    "        base_config['num_heads'] = self.num_heads\n",
    "        base_config['ff_dim'] = self.ff_dim\n",
    "        base_config['rate'] = self.rate\n",
    "        return base_config\n",
    "    \n",
    "    \n",
    "    \n",
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim, **kwargs):\n",
    "        self.maxlen = maxlen\n",
    "        self.embed_dim = embed_dim\n",
    "        super(PositionEmbedding, self).__init__(**kwargs)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = self.maxlen\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(PositionEmbedding, self).get_config()\n",
    "        base_config['maxlen'] = self.maxlen\n",
    "        base_config['embed_dim'] = self.embed_dim\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b701228a-b593-43e5-a4fa-ddf2063b9579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 100, 120)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (None, 100, 120)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_6 (Sli (None, 100, 120)     0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_9 (Sli (None, 100, 120)     0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 100, 120, 1)  0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 100, 120, 1)  0           tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 100, 120, 1)  0           tf.__operators__.getitem_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 100, 120, 1)  0           tf.__operators__.getitem_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 100, 120, 16) 160         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 100, 120, 16) 160         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 100, 120, 16) 160         reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 100, 120, 16) 160         reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 100, 120, 17) 0           reshape[0][0]                    \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 100, 120, 17) 0           reshape_3[0][0]                  \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 100, 120, 17) 0           reshape_6[0][0]                  \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 100, 120, 17) 0           reshape_9[0][0]                  \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 100, 120, 16) 2464        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 100, 120, 16) 2464        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 100, 120, 16) 2464        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 100, 120, 16) 2464        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100, 120, 33) 0           concatenate[0][0]                \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 100, 120, 33) 0           concatenate_4[0][0]              \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 100, 120, 33) 0           concatenate_8[0][0]              \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 100, 120, 33) 0           concatenate_12[0][0]             \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100, 120, 12) 408         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 100, 120, 12) 408         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 100, 120, 12) 408         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 100, 120, 12) 408         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (None, 120, 100, 12) 0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 120)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_1 (TFOpL (None, 120, 100, 12) 0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_4 (Sli (None, 120)          0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_2 (TFOpL (None, 120, 100, 12) 0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_7 (Sli (None, 120)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_3 (TFOpL (None, 120, 100, 12) 0           dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_10 (Sl (None, 120)          0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 120, 1200)    0           tf.compat.v1.transpose[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 120, 1)       0           tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 120, 1200)    0           tf.compat.v1.transpose_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 120, 1)       0           tf.__operators__.getitem_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 120, 1200)    0           tf.compat.v1.transpose_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 120, 1)       0           tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 120, 1200)    0           tf.compat.v1.transpose_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 120, 1)       0           tf.__operators__.getitem_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 120, 1201)    0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 120, 1201)    0           reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 120, 1201)    0           reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 120, 1201)    0           reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 120, 256)     307712      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 120, 256)     307712      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 120, 256)     307712      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 120, 256)     307712      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 120, 256)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 120, 256)     0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 120, 256)     0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 120, 256)     0           dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 120, 128)     32896       leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 120, 128)     32896       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 120, 128)     32896       leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 120, 128)     32896       leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 120, 128)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 120, 128)     0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 120, 128)     0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 120, 128)     0           dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 120, 64)      8256        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 120, 64)      8256        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 120, 64)      8256        leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 120, 64)      8256        leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 120, 64)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 120, 64)      0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 120, 64)      0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 120, 64)      0           dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 120, 64)      128         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 120, 64)      128         leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, 120, 64)      128         leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_21 (LayerNo (None, 120, 64)      128         leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding (PositionEmb (None, 120, 64)      7680        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding_1 (PositionE (None, 120, 64)      7680        layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding_2 (PositionE (None, 120, 64)      7680        layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding_3 (PositionE (None, 120, 64)      7680        layer_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block (TransformerB (None, 120, 64)      166016      position_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_2 (Transforme (None, 120, 64)      166016      position_embedding_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_4 (Transforme (None, 120, 64)      166016      position_embedding_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_6 (Transforme (None, 120, 64)      166016      position_embedding_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_1 (Transforme (None, 120, 64)      166016      transformer_block[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_3 (Transforme (None, 120, 64)      166016      transformer_block_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_5 (Transforme (None, 120, 64)      166016      transformer_block_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_7 (Transforme (None, 120, 64)      166016      transformer_block_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 120, 256)     16640       transformer_block_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 120, 256)     16640       transformer_block_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 120, 256)     16640       transformer_block_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 120, 256)     16640       transformer_block_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 120, 256)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 120, 256)     0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 120, 256)     0           dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 120, 256)     0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 120, 32)      8224        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 120, 32)      8224        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 120, 32)      8224        leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 120, 32)      8224        leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 120, 32)      0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 120, 32)      0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 120, 32)      0           dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 120, 32)      0           dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 120, 16)      528         leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 120, 16)      528         leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 120, 16)      528         leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 120, 16)      528         leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 120, 16)      0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 120, 16)      0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 120, 16)      0           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 120, 16)      0           dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 120, 16)      32          leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, 120, 16)      32          leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, 120, 16)      32          leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_26 (LayerNo (None, 120, 16)      32          leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1920)         0           layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 101)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1920)         0           layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_5 (Sli (None, 101)          0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1920)         0           layer_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_8 (Sli (None, 101)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1920)         0           layer_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_11 (Sl (None, 101)          0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2021)         0           flatten[0][0]                    \n",
      "                                                                 tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 2021)         0           flatten_1[0][0]                  \n",
      "                                                                 tf.__operators__.getitem_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 2021)         0           flatten_2[0][0]                  \n",
      "                                                                 tf.__operators__.getitem_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 2021)         0           flatten_3[0][0]                  \n",
      "                                                                 tf.__operators__.getitem_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         2070528     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1024)         2070528     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 1024)         2070528     concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 1024)         2070528     concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 1024)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 1024)         0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 1024)         0           dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 1024)         0           dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 256)          262400      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 256)          262400      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 256)          262400      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 256)          262400      leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 256)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 256)          0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 256)          0           dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 256)          0           dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 256)          512         leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, 256)          512         leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_20 (LayerNo (None, 256)          512         leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_27 (LayerNo (None, 256)          512         leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 1025)         0           layer_normalization_6[0][0]      \n",
      "                                                                 layer_normalization_13[0][0]     \n",
      "                                                                 layer_normalization_20[0][0]     \n",
      "                                                                 layer_normalization_27[0][0]     \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 1024)         1050624     concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 1024)         0           dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 1024)         1049600     leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 1024)         0           dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 1024)         1049600     leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 1024)         0           dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 2)            2048        leaky_re_lu_34[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 15,354,272\n",
      "Trainable params: 15,354,272\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def proc_chart(x):\n",
    "    #x1 = image\n",
    "    #x2 = time\n",
    "    x1 = x[::, :-1, :-1]\n",
    "    x2 = x[::,-1,:-1]\n",
    "    current_pos = x[::,::, -1]\n",
    "\n",
    "    x1 = tf.keras.layers.Reshape((res_high, dlen, 1))(x1)\n",
    "    \n",
    "    x5 = tf.keras.layers.Conv2D(16, 3,activation=\"relu\", padding=\"same\")(x1)\n",
    "    x1 = tf.keras.layers.Concatenate()([x1,x5])\n",
    "    x5 = tf.keras.layers.Conv2D(16, 3,activation=\"relu\", padding=\"same\")(x1)\n",
    "    x1 = tf.keras.layers.Concatenate()([x1,x5])\n",
    "    #x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    x1 = tf.keras.layers.Dense(12)(x1)\n",
    "    \n",
    "    x1 = tf.transpose(x1,perm=[0, 2, 1, 3])\n",
    "    x1 = tf.keras.layers.Reshape((dlen, res_high*x1.shape[-1]))(x1)\n",
    "    x2 = tf.keras.layers.Reshape((dlen, 1))(x2)\n",
    "    x1 = tf.keras.layers.Concatenate()([x1,x2])\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(256)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(128)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(64)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    \n",
    "    \n",
    "    x1 = PositionEmbedding(dlen, x1.shape[-1])(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "\n",
    "    x1 = tf.keras.layers.Dense(256)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(32)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(16)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Concatenate()([x1,current_pos])\n",
    "    x1 = tf.keras.layers.Dense(1024)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(256)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    return x1\n",
    "    \n",
    "if True:\n",
    "    input_m15 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h4 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_d1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    \n",
    "    x1 = proc_chart(input_m15)\n",
    "    x2 = proc_chart(input_h1)\n",
    "    x3 = proc_chart(input_h4)\n",
    "    x4 = proc_chart(input_d1)\n",
    "    \n",
    "    input_net_position = tf.keras.layers.Input(shape = (1))\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Concatenate()([x1,x2,x3,x4,input_net_position])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(2, activation = \"linear\", use_bias=False, dtype=\"float32\")(x)\n",
    "    model = tf.keras.Model([input_m15,input_h1,input_h4, input_d1, input_net_position], outputs)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4835645d-95a9-484d-b4d3-04ce14fb2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#states = m15candles, h1candles, h4candles, d1candles, position\n",
    "#states =(5,dlen), (5,dlen), (5,dlen), (5,dlen), (1)\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, model,\n",
    "                 n_actions,\n",
    "                 memory_size = 100000, \n",
    "                 optimizer = tf.keras.optimizers.Adam(0.0005), \n",
    "                 gamma = 0.99,\n",
    "                 batch_size =32,\n",
    "                 name = \"dqn1\",\n",
    "                 target_model_sync = 1000,\n",
    "                 exploration = 0.01\n",
    "                ):\n",
    "        self.exploration = exploration\n",
    "        self.gamma = gamma\n",
    "        self.n_actions = n_actions\n",
    "        self.batch_size = batch_size\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.memory_size = memory_size\n",
    "        self.optimizer = optimizer\n",
    "        self.m1 = np.eye(self.n_actions, dtype=\"float32\")\n",
    "        self.target_model = tf.keras.models.clone_model(self.model)\n",
    "        self.target_model_sync = target_model_sync\n",
    "   \n",
    "        self.memory = deque(maxlen = self.memory_size)\n",
    "      \n",
    "    \n",
    "    def copy_weights(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "      \n",
    "    def load_weights(self):\n",
    "        self.model.load_weights(self.name)\n",
    "    def save_weights(self):\n",
    "        self.model.save_weights(self.name, overwrite = True)\n",
    "        \n",
    "    @tf.function(jit_compile = True)\n",
    "    def model_call(self, x):\n",
    "        x1, x2, x3, x4, x5 = x\n",
    "        return tf.math.argmax(self.model([x1,x2,x3,x4,x5]), axis = 1)\n",
    "    \n",
    "    def select_actions(self, state1, state2, state3, state4, state5):\n",
    "        if np.random.random() < self.exploration: # random action\n",
    "            return [np.random.randint(0,self.n_actions) for _ in range(len(state5))]\n",
    "        \n",
    "        ret = self.model_call([state1, state2, state3, state4, state5])\n",
    "        return ret.numpy()\n",
    "\n",
    "\n",
    "        \n",
    "    def observe_sasrt(self, state, action, next_state, reward, terminal):\n",
    "        self.memory.append([state, action, reward, 1-int(terminal), next_state])\n",
    "        \n",
    "    @tf.function(jit_compile = True)\n",
    "    def get_target_q(self, next_states, rewards, terminals):\n",
    "        estimated_q_values_next = self.target_model(next_states)\n",
    "        q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
    "        target_q_values = q_batch * self.gamma * terminals + rewards\n",
    "        return target_q_values\n",
    "\n",
    "        \n",
    "    @tf.function(jit_compile = True)\n",
    "    def tstep(self, data):\n",
    "        states, next_states, rewards, terminals, masks = data\n",
    "        target_q_values = self.get_target_q(next_states, rewards, terminals)\n",
    "        \n",
    "        with tf.GradientTape() as t:\n",
    "            model_return = self.model(states, training=True) \n",
    "            mask_return = model_return * masks\n",
    "            estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
    "            #print(estimated_q_values, mask_return, model_return, masks)\n",
    "            loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
    "            loss = tf.reduce_mean(loss_e)\n",
    "        \n",
    "        \n",
    "        gradient = t.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradient, self.model.trainable_variables))\n",
    "        \n",
    "        return loss, tf.reduce_mean(estimated_q_values)\n",
    "    \n",
    "    \n",
    "    def data_get_func(self):\n",
    "        idx = np.random.randint(0, len(self.memory), self.batch_size)\n",
    "        sarts_batch = [self.memory[i] for i in idx]\n",
    "        \n",
    "        states = [x[0] for x in sarts_batch]\n",
    "        states_1 = np.array([x[0] for x in states], dtype=\"float32\")\n",
    "        states_2 = np.array([x[1] for x in states], dtype=\"float32\")\n",
    "        states_3 = np.array([x[2] for x in states], dtype=\"float32\")\n",
    "        states_4 = np.array([x[3] for x in states], dtype=\"float32\")\n",
    "        states_5 = np.array([x[4] for x in states], dtype=\"float32\")\n",
    "        \n",
    "        actions = [x[1] for x in sarts_batch]\n",
    "        rewards = np.array([x[2] for x in sarts_batch], dtype=\"float32\")\n",
    "        terminals = np.array([x[3] for x in sarts_batch], dtype=\"float32\")\n",
    "        \n",
    "        next_states = [x[4] for x in sarts_batch]\n",
    "        next_states_1 = np.array([x[0] for x in next_states], dtype=\"float32\")\n",
    "        next_states_2 = np.array([x[1] for x in next_states], dtype=\"float32\")\n",
    "        next_states_3 = np.array([x[2] for x in next_states], dtype=\"float32\")\n",
    "        next_states_4 = np.array([x[3] for x in next_states], dtype=\"float32\")\n",
    "        next_states_5 = np.array([x[4] for x in next_states], dtype=\"float32\")\n",
    "        #print(actions)\n",
    "        masks = np.array(self.m1[actions])\n",
    "        return [states_1, states_2, states_3, states_4, states_5], [next_states_1, next_states_2, next_states_3, next_states_4, next_states_5], rewards, terminals, masks\n",
    "\n",
    "    def update_parameters(self):\n",
    "        self.total_steps_trained+=1\n",
    "        if self.total_steps_trained % self.target_model_sync == 0:\n",
    "            self.copy_weights()\n",
    "\n",
    "           \n",
    "        data = self.data_get_func()\n",
    "        result= self.tstep(data)\n",
    "   \n",
    "        return  result\n",
    "    \n",
    "    def train(self, num_steps, envs, log_interval = 1000, warmup = 0, train_steps_per_step = 1):\n",
    "        self.total_steps_trained = -1\n",
    "\n",
    "        num_envs = len(envs)\n",
    "        states = [x.reset(True) for x in envs]\n",
    "        \n",
    "        current_episode_reward_sum = 0\n",
    "        times= deque(maxlen=10)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.longs = 0\n",
    "        self.shorts = 0\n",
    "\n",
    "        self.total_rewards = []\n",
    "        self.losses = [0]\n",
    "        self.q_v = [0]\n",
    "        \n",
    "        def save_current_run():\n",
    "            self.save_weights()\n",
    "            file = open(log_folder+\"logs/loss_log.txt\", \"a\")  \n",
    "            #for loss in self.losses:\n",
    "                        #file.write(str(loss))\n",
    "                        #file.write(\"\\n\")\n",
    "            file.write(str(np.mean(self.losses)))\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "\n",
    "            file = open(log_folder+\"logs/qv_log.txt\", \"a\")  \n",
    "            #for qv in self.q_v:\n",
    "                        #file.write(str(qv))\n",
    "                        #file.write(\"\\n\")\n",
    "            file.write(str(np.mean(self.q_v)))\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "\n",
    "            file = open(log_folder+\"logs/rewards_log.txt\", \"a\")  \n",
    "            #for total_reward in self.total_rewards:\n",
    "                        #file.write(str(total_reward))\n",
    "                        #file.write(\"\\n\")\n",
    "                    \n",
    "            file.write(str(np.mean(self.total_rewards)))\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "            \n",
    "    \n",
    "\n",
    "            self.total_rewards = []\n",
    "            self.losses = [0]\n",
    "            self.q_v = [0]\n",
    "        \n",
    "        try:\n",
    "            for i in range(num_steps):\n",
    "                if i % log_interval == 0:\n",
    "                    progbar = tf.keras.utils.Progbar(log_interval, interval=0.1, stateful_metrics = [\"reward sum\", \"t\", \"l/s\"])\n",
    "                    self.longs = 0\n",
    "                    self.shorts = 0\n",
    "\n",
    "\n",
    "                states_1 = np.array([x[0] for x in states])\n",
    "                states_2 = np.array([x[1] for x in states])\n",
    "                states_3 = np.array([x[2] for x in states])\n",
    "                states_4 = np.array([x[3] for x in states])\n",
    "                states_5 = np.array([x[4] for x in states])\n",
    "                \n",
    "                actions = self.select_actions(states_1, states_2, states_3, states_4, states_5)\n",
    "                for action in actions:\n",
    "                    if action == 0:\n",
    "                        self.shorts+=1\n",
    "                    elif action == 1:\n",
    "                        self.longs+=1\n",
    "\n",
    "                sasrt_pairs = []\n",
    "                for index in range(num_envs):\n",
    "                    sasrt_pairs.append([states[index], actions[index]]+[x for x in envs[index].step(actions[index])])\n",
    "\n",
    "                next_states = [x[2] for x in sasrt_pairs]\n",
    "\n",
    "                reward = [x[3] for x in sasrt_pairs]\n",
    "                current_episode_reward_sum += np.sum(reward)\n",
    "\n",
    "                self.total_rewards.extend(reward)\n",
    "\n",
    "                for index, o in enumerate(sasrt_pairs):\n",
    "                    #print(o)\n",
    "                    if o[4] == True:\n",
    "                        next_states[index] = envs[index].reset()\n",
    "                    self.observe_sasrt(o[0], o[1], o[2], o[3], o[4])\n",
    "\n",
    "                states = next_states\n",
    "                if i > warmup:\n",
    "                    for _ in range(train_steps_per_step):\n",
    "                        loss, q = self.update_parameters()\n",
    "                        self.losses.append(loss.numpy())\n",
    "                        self.q_v.append(q.numpy())\n",
    "                else:\n",
    "                    loss, q = 0, 0\n",
    "\n",
    "                end_time = time.time()\n",
    "                elapsed = (end_time - start_time) * 1000\n",
    "                times.append(elapsed)\n",
    "                start_time = end_time\n",
    "\n",
    "\n",
    "                if (i+1) % log_interval == 0:\n",
    "                    #print(\"-----------\")\n",
    "                    #print(\"l:\", np.mean(self.losses))\n",
    "                    #print(\"q:\", np.mean(self.q_v))\n",
    "                    #print(\"reward sum\", current_episode_reward_sum)\n",
    "                    #print(\"l/s\", (self.longs - self.shorts) / (1+self.longs+self.shorts))\n",
    "                    #print(\"t\", np.mean(times))\n",
    "                    #print(\"-----------\")\n",
    "                    save_current_run()\n",
    "\n",
    "                progbar.update(i%log_interval+1, values = \n",
    "                               [(\"loss\", np.mean(self.losses[-train_steps_per_step:])),\n",
    "                                (\"mean q\", np.mean(self.q_v[-train_steps_per_step:])),\n",
    "                                (\"rewards\", np.mean(reward)),\n",
    "                                (\"reward sum\", current_episode_reward_sum),\n",
    "                                (\"l/s\", (self.longs - self.shorts) / (1+self.longs+self.shorts)),\n",
    "                                (\"t\", np.mean(times))])\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nbreak!\")\n",
    "        \n",
    "        save_current_run()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4db0d3e-7df8-4a56-b06c-ea9aeb7a1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "\n",
    "log_folder = \"./\"\n",
    "\n",
    "agent = DQNAgent(\n",
    "    model = model, \n",
    "    n_actions = 2, \n",
    "    memory_size = memory_size, \n",
    "    gamma=gamma,\n",
    "    optimizer = opt,\n",
    "    batch_size = batch_size, \n",
    "    target_model_sync = target_model_sync,\n",
    "    exploration = exploration,\n",
    "    name=log_folder+name+\".h5\")\n",
    "\n",
    "if resume:\n",
    "\tprint(\"loading weights...\")\n",
    "\tagent.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411125ec-439f-4de3-bcc3-4e0abf9d3304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup...\n",
      "using ./archive/15_USDJPY.csv_candle_classes\n",
      "using ./archive/15_EURCHF.csv_candle_classes\n",
      "using ./archive/15_AUDUSD.csv_candle_classes\n",
      "using ./archive/15_AUDJPY.csv_candle_classes\n",
      "1000/1000 [==============================] - 27s 22ms/step - loss: 0.0000e+00 - mean q: 0.0000e+00 - rewards: -0.0553 - reward sum: -221.2176 - l/s: -0.7833 - t: 21.6720\n"
     ]
    }
   ],
   "source": [
    "x = [environment() for _ in range(warmup_parallel)]\n",
    "print(\"warmup...\")\n",
    "n = warmup_steps\n",
    "agent.train(num_steps = n, envs = x, warmup = n, log_interval = n, train_steps_per_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abb27070-100e-4c75-b51d-3d30d7132ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a81a7b-54d5-4796-b801-0e98ffee8890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "using ./archive/15_EURAUD.csv_candle_classes\n",
      "using ./archive/15_USDJPY.csv_candle_classes\n",
      "using ./archive/15_CHFJPY.csv_candle_classes\n",
      "using ./archive/15_EURAUD.csv_candle_classes\n",
      "1000/1000 [==============================] - 406s 406ms/step - loss: 1.3656 - mean q: 0.0853 - rewards: -0.0818 - reward sum: -327.2723 - l/s: -0.0955 - t: 386.5357\n",
      "1000/1000 [==============================] - 388s 388ms/step - loss: 0.8370 - mean q: 0.0638 - rewards: -0.1221 - reward sum: -815.7259 - l/s: -0.1390 - t: 390.2117\n",
      "1000/1000 [==============================] - 378s 378ms/step - loss: 0.7646 - mean q: 0.0587 - rewards: -0.1082 - reward sum: -1248.6693 - l/s: -0.1765 - t: 354.1511\n",
      "1000/1000 [==============================] - 355s 355ms/step - loss: 0.6186 - mean q: 0.0497 - rewards: -0.0613 - reward sum: -1493.8076 - l/s: -0.1285 - t: 359.3555\n",
      "1000/1000 [==============================] - 355s 355ms/step - loss: 0.7059 - mean q: 0.0664 - rewards: -0.1070 - reward sum: -1922.0045 - l/s: -0.0545 - t: 358.1585\n",
      "1000/1000 [==============================] - 368s 368ms/step - loss: 1.3299 - mean q: 0.5146 - rewards: -0.0709 - reward sum: -2205.5665 - l/s: -0.1335 - t: 360.7866\n",
      "1000/1000 [==============================] - 370s 370ms/step - loss: 0.8976 - mean q: 0.5077 - rewards: -0.0617 - reward sum: -2452.1915 - l/s: -0.1195 - t: 363.2693\n",
      "1000/1000 [==============================] - 371s 371ms/step - loss: 0.7791 - mean q: 0.4868 - rewards: -0.0812 - reward sum: -2776.8507 - l/s: -0.0740 - t: 371.5033\n",
      "1000/1000 [==============================] - 376s 376ms/step - loss: 0.6469 - mean q: 0.4562 - rewards: -0.0829 - reward sum: -3108.4619 - l/s: -0.0665 - t: 383.9658\n",
      "1000/1000 [==============================] - 392s 392ms/step - loss: 0.6669 - mean q: 0.4473 - rewards: -0.0814 - reward sum: -3434.1744 - l/s: -0.0720 - t: 401.9355\n",
      "1000/1000 [==============================] - 407s 407ms/step - loss: 1.6457 - mean q: 0.5689 - rewards: -0.0732 - reward sum: -3727.0342 - l/s: 0.0415 - t: 413.1425\n",
      "1000/1000 [==============================] - 419s 419ms/step - loss: 0.8777 - mean q: 0.5323 - rewards: -0.1297 - reward sum: -4245.9822 - l/s: 0.0160 - t: 425.7767\n",
      "1000/1000 [==============================] - 432s 432ms/step - loss: 0.7466 - mean q: 0.5064 - rewards: -0.1462 - reward sum: -4830.6895 - l/s: 0.0740 - t: 439.4149\n",
      "1000/1000 [==============================] - 444s 444ms/step - loss: 0.8434 - mean q: 0.4972 - rewards: -0.1154 - reward sum: -5292.4238 - l/s: 0.0665 - t: 448.9635\n",
      "1000/1000 [==============================] - 457s 457ms/step - loss: 0.6794 - mean q: 0.5046 - rewards: -0.1025 - reward sum: -5702.6173 - l/s: 0.0610 - t: 462.0201\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 1.3492 - mean q: 0.9002 - rewards: -0.1185 - reward sum: -6176.4754 - l/s: 0.1545 - t: 452.1373\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 0.7270 - mean q: 0.9089 - rewards: -0.0812 - reward sum: -6501.1302 - l/s: 0.1845 - t: 442.6227\n",
      "1000/1000 [==============================] - 460s 460ms/step - loss: 0.5584 - mean q: 0.8979 - rewards: -0.0827 - reward sum: -6831.9386 - l/s: 0.2409 - t: 461.4751\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 0.5308 - mean q: 0.8947 - rewards: -0.0935 - reward sum: -7206.0056 - l/s: 0.2199 - t: 456.7740\n",
      "1000/1000 [==============================] - 457s 457ms/step - loss: 0.5067 - mean q: 0.9143 - rewards: -0.0700 - reward sum: -7485.9385 - l/s: 0.1815 - t: 458.3289\n",
      "1000/1000 [==============================] - 462s 462ms/step - loss: 1.3445 - mean q: 1.2625 - rewards: -0.1060 - reward sum: -7910.0162 - l/s: 0.3404 - t: 462.9001\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 0.6478 - mean q: 1.2329 - rewards: -0.0838 - reward sum: -8245.1220 - l/s: 0.3459 - t: 459.7226\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 0.4928 - mean q: 1.2242 - rewards: -0.1107 - reward sum: -8687.9977 - l/s: 0.3294 - t: 459.5856\n",
      "1000/1000 [==============================] - 458s 458ms/step - loss: 0.4699 - mean q: 1.2175 - rewards: -0.0741 - reward sum: -8984.5017 - l/s: 0.3004 - t: 459.9664\n",
      "1000/1000 [==============================] - 461s 461ms/step - loss: 0.4743 - mean q: 1.2255 - rewards: -0.0691 - reward sum: -9260.8311 - l/s: 0.3529 - t: 464.4781\n",
      "1000/1000 [==============================] - 461s 461ms/step - loss: 1.2713 - mean q: 1.3715 - rewards: -0.0989 - reward sum: -9656.3995 - l/s: 0.1730 - t: 451.0184\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 1.1474 - mean q: 1.3761 - rewards: -0.0644 - reward sum: -9914.1548 - l/s: 0.1775 - t: 459.8197\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 2.0813 - mean q: 1.3702 - rewards: -0.0260 - reward sum: -10017.9848 - l/s: 0.1670 - t: 458.4922\n",
      "1000/1000 [==============================] - 461s 461ms/step - loss: 1.7930 - mean q: 1.3746 - rewards: -0.0794 - reward sum: -10335.4812 - l/s: 0.1370 - t: 461.3286\n",
      "1000/1000 [==============================] - 461s 461ms/step - loss: 1.5420 - mean q: 1.3614 - rewards: -0.0767 - reward sum: -10642.1597 - l/s: 0.2004 - t: 459.1472\n",
      "1000/1000 [==============================] - 462s 462ms/step - loss: 3.1584 - mean q: 1.7139 - rewards: -0.1112 - reward sum: -11086.8706 - l/s: 0.0780 - t: 461.3585\n",
      "1000/1000 [==============================] - 458s 458ms/step - loss: 1.8778 - mean q: 1.7282 - rewards: -0.0755 - reward sum: -11388.9144 - l/s: 0.1390 - t: 459.7871\n",
      "1000/1000 [==============================] - 458s 458ms/step - loss: 1.4771 - mean q: 1.7089 - rewards: -0.0483 - reward sum: -11582.2095 - l/s: 0.1280 - t: 456.6638\n",
      "1000/1000 [==============================] - 457s 457ms/step - loss: 1.3231 - mean q: 1.6694 - rewards: -0.0726 - reward sum: -11872.5443 - l/s: 0.1670 - t: 456.5849\n",
      "1000/1000 [==============================] - 457s 457ms/step - loss: 1.2740 - mean q: 1.6675 - rewards: -0.0844 - reward sum: -12210.1765 - l/s: 0.0820 - t: 459.4584\n",
      "1000/1000 [==============================] - 457s 457ms/step - loss: 2.3544 - mean q: 1.7725 - rewards: -0.0504 - reward sum: -12411.6983 - l/s: 0.1205 - t: 448.8537\n",
      "1000/1000 [==============================] - 456s 456ms/step - loss: 1.2554 - mean q: 1.7586 - rewards: -0.0815 - reward sum: -12737.7610 - l/s: 0.1465 - t: 452.0460\n",
      "1000/1000 [==============================] - 463s 463ms/step - loss: 0.8531 - mean q: 1.7193 - rewards: -0.0863 - reward sum: -13083.0237 - l/s: 0.1920 - t: 459.3935\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 0.7249 - mean q: 1.7020 - rewards: -0.0670 - reward sum: -13350.9866 - l/s: 0.1790 - t: 456.9109\n",
      "1000/1000 [==============================] - 457s 457ms/step - loss: 0.6763 - mean q: 1.6821 - rewards: -0.1190 - reward sum: -13827.1526 - l/s: 0.1730 - t: 456.8091\n",
      "1000/1000 [==============================] - 455s 455ms/step - loss: 1.9669 - mean q: 1.9189 - rewards: -0.0900 - reward sum: -14186.9846 - l/s: 0.0410 - t: 447.1861\n",
      "1000/1000 [==============================] - 452s 452ms/step - loss: 1.0071 - mean q: 1.8674 - rewards: -0.0834 - reward sum: -14520.5518 - l/s: 0.0455 - t: 453.5673\n",
      "1000/1000 [==============================] - 451s 451ms/step - loss: 0.6713 - mean q: 1.8603 - rewards: -0.0772 - reward sum: -14829.4252 - l/s: 0.0770 - t: 450.4002\n",
      "1000/1000 [==============================] - 451s 451ms/step - loss: 0.6205 - mean q: 1.8092 - rewards: -0.1316 - reward sum: -15355.9806 - l/s: 0.0735 - t: 455.3014\n",
      "1000/1000 [==============================] - 452s 452ms/step - loss: 0.5176 - mean q: 1.7806 - rewards: -0.0733 - reward sum: -15649.0658 - l/s: 0.1105 - t: 487.6341\n",
      "1000/1000 [==============================] - 460s 460ms/step - loss: 1.2681 - mean q: 1.9114 - rewards: -0.1417 - reward sum: -16215.7386 - l/s: 0.0625 - t: 448.9808\n",
      "1000/1000 [==============================] - 449s 449ms/step - loss: 0.6482 - mean q: 1.8823 - rewards: -0.1104 - reward sum: -16657.3227 - l/s: 0.0370 - t: 447.9828\n",
      "1000/1000 [==============================] - 445s 445ms/step - loss: 0.5341 - mean q: 1.8666 - rewards: -0.0915 - reward sum: -17023.2055 - l/s: 0.0615 - t: 437.9236\n",
      "1000/1000 [==============================] - 447s 447ms/step - loss: 0.4914 - mean q: 1.8527 - rewards: -0.1238 - reward sum: -17518.2099 - l/s: 0.0640 - t: 447.6020\n",
      "1000/1000 [==============================] - 446s 446ms/step - loss: 0.6135 - mean q: 1.8620 - rewards: -0.0594 - reward sum: -17755.8116 - l/s: -0.0390 - t: 445.7687\n",
      "1000/1000 [==============================] - 446s 446ms/step - loss: 1.2205 - mean q: 1.9512 - rewards: -0.0855 - reward sum: -18098.0102 - l/s: 0.1160 - t: 446.0331\n",
      "1000/1000 [==============================] - 445s 445ms/step - loss: 0.6091 - mean q: 1.9277 - rewards: -0.0975 - reward sum: -18488.1102 - l/s: 0.1100 - t: 448.7870\n",
      "1000/1000 [==============================] - 445s 445ms/step - loss: 0.5722 - mean q: 1.9172 - rewards: -0.1133 - reward sum: -18941.3162 - l/s: 0.1100 - t: 437.8556\n",
      "1000/1000 [==============================] - 445s 445ms/step - loss: 0.5001 - mean q: 1.9166 - rewards: -0.1403 - reward sum: -19502.6750 - l/s: 0.1310 - t: 445.7692\n",
      "1000/1000 [==============================] - 446s 446ms/step - loss: 0.4213 - mean q: 1.9212 - rewards: -0.1304 - reward sum: -20024.3147 - l/s: 0.1065 - t: 445.6796\n",
      "1000/1000 [==============================] - 442s 442ms/step - loss: 1.3116 - mean q: 1.9685 - rewards: -0.1144 - reward sum: -20482.0044 - l/s: 0.0760 - t: 434.8078\n",
      "1000/1000 [==============================] - 443s 443ms/step - loss: 0.9700 - mean q: 1.9526 - rewards: -0.0838 - reward sum: -20817.0244 - l/s: 0.0855 - t: 442.5741\n",
      "1000/1000 [==============================] - 442s 442ms/step - loss: 0.4670 - mean q: 1.9332 - rewards: -0.0839 - reward sum: -21152.4691 - l/s: 0.0625 - t: 441.0529\n",
      "1000/1000 [==============================] - 441s 441ms/step - loss: 0.3984 - mean q: 1.9335 - rewards: -0.0901 - reward sum: -21512.9347 - l/s: 0.0160 - t: 437.8612\n",
      "1000/1000 [==============================] - 441s 441ms/step - loss: 0.4206 - mean q: 1.9195 - rewards: -0.1017 - reward sum: -21919.8715 - l/s: 0.0605 - t: 441.0154\n",
      "1000/1000 [==============================] - 440s 440ms/step - loss: 1.0085 - mean q: 1.9819 - rewards: -0.0947 - reward sum: -22298.5454 - l/s: 0.1460 - t: 434.0800\n",
      "1000/1000 [==============================] - 441s 441ms/step - loss: 0.5164 - mean q: 1.9975 - rewards: -0.0826 - reward sum: -22628.8825 - l/s: 0.1935 - t: 442.3333\n",
      "1000/1000 [==============================] - 440s 440ms/step - loss: 0.4623 - mean q: 1.9905 - rewards: -0.0812 - reward sum: -22953.5527 - l/s: 0.1590 - t: 437.9207\n",
      "1000/1000 [==============================] - 438s 438ms/step - loss: 0.3653 - mean q: 1.9723 - rewards: -0.1055 - reward sum: -23375.4648 - l/s: 0.1635 - t: 436.2659\n",
      "1000/1000 [==============================] - 438s 438ms/step - loss: 0.3283 - mean q: 1.9611 - rewards: -0.0985 - reward sum: -23769.4302 - l/s: 0.1595 - t: 437.9185\n",
      "1000/1000 [==============================] - 470s 470ms/step - loss: 0.8956 - mean q: 1.9581 - rewards: -0.0914 - reward sum: -24134.9209 - l/s: -0.0470 - t: 457.7106\n",
      "1000/1000 [==============================] - 456s 456ms/step - loss: 0.6355 - mean q: 1.9367 - rewards: -0.0442 - reward sum: -24311.8556 - l/s: 0.0125 - t: 444.5891\n",
      "1000/1000 [==============================] - 451s 451ms/step - loss: 0.5673 - mean q: 1.9240 - rewards: -0.1126 - reward sum: -24762.4087 - l/s: -0.0205 - t: 440.9738\n",
      "1000/1000 [==============================] - 447s 447ms/step - loss: 0.4295 - mean q: 1.9037 - rewards: -0.0789 - reward sum: -25077.8588 - l/s: 0.0040 - t: 447.2977\n",
      "1000/1000 [==============================] - 447s 447ms/step - loss: 0.3638 - mean q: 1.9124 - rewards: -0.0907 - reward sum: -25440.5104 - l/s: -0.0090 - t: 447.1046\n",
      "1000/1000 [==============================] - 447s 447ms/step - loss: 1.0498 - mean q: 2.1359 - rewards: -0.0746 - reward sum: -25738.8453 - l/s: 9.9975e-04 - t: 448.8580\n",
      "1000/1000 [==============================] - 448s 448ms/step - loss: 0.5852 - mean q: 2.1339 - rewards: -0.1035 - reward sum: -26152.6769 - l/s: -0.0185 - t: 448.7087\n",
      "1000/1000 [==============================] - 447s 447ms/step - loss: 0.4415 - mean q: 2.1197 - rewards: -0.0947 - reward sum: -26531.5752 - l/s: -0.0380 - t: 447.1153\n",
      "1000/1000 [==============================] - 446s 446ms/step - loss: 0.4007 - mean q: 2.1170 - rewards: -0.1245 - reward sum: -27029.5249 - l/s: -0.0510 - t: 447.1422\n",
      "1000/1000 [==============================] - 446s 446ms/step - loss: 0.3562 - mean q: 2.0991 - rewards: -0.0760 - reward sum: -27333.3399 - l/s: 0.0065 - t: 444.1482\n",
      "1000/1000 [==============================] - 448s 448ms/step - loss: 0.8808 - mean q: 2.1943 - rewards: -0.0937 - reward sum: -27708.3081 - l/s: -0.0030 - t: 445.7990\n",
      "1000/1000 [==============================] - 447s 447ms/step - loss: 0.4829 - mean q: 2.1959 - rewards: -0.0753 - reward sum: -28009.3561 - l/s: 0.0315 - t: 437.9030\n",
      "1000/1000 [==============================] - 447s 447ms/step - loss: 0.4082 - mean q: 2.1903 - rewards: -0.0921 - reward sum: -28377.8658 - l/s: 0.0280 - t: 439.4846\n",
      "1000/1000 [==============================] - 444s 444ms/step - loss: 0.3794 - mean q: 2.1827 - rewards: -0.0774 - reward sum: -28687.4952 - l/s: 0.0470 - t: 444.2210\n",
      "1000/1000 [==============================] - 441s 441ms/step - loss: 0.3385 - mean q: 2.1681 - rewards: -0.0612 - reward sum: -28932.2800 - l/s: 0.0440 - t: 442.6753\n",
      "1000/1000 [==============================] - 442s 442ms/step - loss: 0.9458 - mean q: 2.2875 - rewards: -0.0682 - reward sum: -29205.2261 - l/s: 0.0135 - t: 441.8121\n",
      "1000/1000 [==============================] - 440s 440ms/step - loss: 0.5792 - mean q: 2.2844 - rewards: -0.0708 - reward sum: -29488.4807 - l/s: 0.0600 - t: 441.0818\n",
      "1000/1000 [==============================] - 442s 442ms/step - loss: 0.4388 - mean q: 2.2657 - rewards: -0.1078 - reward sum: -29919.8089 - l/s: 0.0310 - t: 442.7962\n",
      "1000/1000 [==============================] - 441s 441ms/step - loss: 0.4172 - mean q: 2.2602 - rewards: -0.1151 - reward sum: -30380.1433 - l/s: 0.0185 - t: 439.4066\n",
      "1000/1000 [==============================] - 470s 470ms/step - loss: 0.4013 - mean q: 2.2513 - rewards: -0.0801 - reward sum: -30700.5167 - l/s: -0.0190 - t: 459.7111\n",
      "1000/1000 [==============================] - 462s 462ms/step - loss: 1.0630 - mean q: 2.4012 - rewards: -0.0811 - reward sum: -31025.0436 - l/s: -0.0615 - t: 430.3019\n",
      "1000/1000 [==============================] - 440s 440ms/step - loss: 0.5757 - mean q: 2.3735 - rewards: -0.0919 - reward sum: -31392.5525 - l/s: -0.0275 - t: 447.5003\n",
      "1000/1000 [==============================] - 439s 439ms/step - loss: 0.5218 - mean q: 2.3422 - rewards: -0.0889 - reward sum: -31748.1065 - l/s: -0.0590 - t: 425.3037\n",
      "1000/1000 [==============================] - 438s 438ms/step - loss: 0.5149 - mean q: 2.3240 - rewards: -0.1003 - reward sum: -32149.3603 - l/s: -0.0675 - t: 441.2006\n",
      "1000/1000 [==============================] - 444s 444ms/step - loss: 0.4970 - mean q: 2.2966 - rewards: -0.1369 - reward sum: -32696.9579 - l/s: -0.0500 - t: 441.7644\n",
      "1000/1000 [==============================] - 445s 445ms/step - loss: 1.2079 - mean q: 2.4129 - rewards: -0.1085 - reward sum: -33131.1122 - l/s: -0.0815 - t: 445.6450\n",
      "1000/1000 [==============================] - 460s 460ms/step - loss: 0.6935 - mean q: 2.3723 - rewards: -0.1185 - reward sum: -33605.2115 - l/s: -0.1100 - t: 472.4237\n",
      "1000/1000 [==============================] - 479s 479ms/step - loss: 0.5498 - mean q: 2.3720 - rewards: -0.1017 - reward sum: -34011.8669 - l/s: -0.0275 - t: 477.8412\n",
      "1000/1000 [==============================] - 477s 477ms/step - loss: 0.6121 - mean q: 2.3667 - rewards: -0.0779 - reward sum: -34323.3761 - l/s: -0.0875 - t: 467.0568\n",
      "1000/1000 [==============================] - 476s 476ms/step - loss: 0.6124 - mean q: 2.3425 - rewards: -0.1341 - reward sum: -34859.6387 - l/s: -0.0590 - t: 471.6202\n",
      "1000/1000 [==============================] - 473s 473ms/step - loss: 1.7288 - mean q: 2.5070 - rewards: -0.0649 - reward sum: -35119.0442 - l/s: -0.0580 - t: 472.7582\n",
      "1000/1000 [==============================] - 468s 468ms/step - loss: 1.4644 - mean q: 2.4653 - rewards: -0.0592 - reward sum: -35355.7740 - l/s: -0.0165 - t: 469.0093\n",
      "1000/1000 [==============================] - 463s 463ms/step - loss: 1.2171 - mean q: 2.4463 - rewards: -0.1027 - reward sum: -35766.6310 - l/s: -0.0155 - t: 448.3979\n",
      "1000/1000 [==============================] - 441s 441ms/step - loss: 1.0081 - mean q: 2.4490 - rewards: -0.1342 - reward sum: -36303.4889 - l/s: -0.0350 - t: 433.0425\n",
      "1000/1000 [==============================] - 441s 441ms/step - loss: 0.9214 - mean q: 2.4349 - rewards: -0.1205 - reward sum: -36785.5497 - l/s: -0.0255 - t: 442.7764\n",
      "1000/1000 [==============================] - 444s 444ms/step - loss: 2.4390 - mean q: 2.6202 - rewards: -0.0886 - reward sum: -37139.7734 - l/s: -0.1090 - t: 462.4101\n",
      "1000/1000 [==============================] - 455s 454ms/step - loss: 1.3527 - mean q: 2.5921 - rewards: -0.0511 - reward sum: -37344.0705 - l/s: -0.1075 - t: 445.9467\n",
      "1000/1000 [==============================] - 438s 438ms/step - loss: 1.2596 - mean q: 2.5665 - rewards: -0.1085 - reward sum: -37778.2389 - l/s: -0.1015 - t: 434.9863\n",
      "1000/1000 [==============================] - 432s 432ms/step - loss: 0.9974 - mean q: 2.5477 - rewards: -0.0731 - reward sum: -38070.5249 - l/s: -0.1255 - t: 431.0836\n",
      "1000/1000 [==============================] - 435s 435ms/step - loss: 0.8552 - mean q: 2.5048 - rewards: -0.1220 - reward sum: -38558.3303 - l/s: -0.0465 - t: 433.8725\n",
      "1000/1000 [==============================] - 435s 435ms/step - loss: 2.1790 - mean q: 2.7076 - rewards: -0.0550 - reward sum: -38778.1807 - l/s: -0.0465 - t: 443.8363\n",
      "1000/1000 [==============================] - 433s 433ms/step - loss: 1.1289 - mean q: 2.6895 - rewards: -0.1147 - reward sum: -39236.9821 - l/s: -0.0730 - t: 430.0667\n",
      "1000/1000 [==============================] - 430s 430ms/step - loss: 0.8203 - mean q: 2.6847 - rewards: -0.0711 - reward sum: -39521.5554 - l/s: -0.0550 - t: 431.6731\n",
      "1000/1000 [==============================] - 431s 431ms/step - loss: 0.7092 - mean q: 2.6699 - rewards: -0.1102 - reward sum: -39962.1745 - l/s: -0.0265 - t: 436.3433\n",
      "1000/1000 [==============================] - 430s 430ms/step - loss: 0.7040 - mean q: 2.6484 - rewards: -0.0945 - reward sum: -40340.3450 - l/s: -0.0240 - t: 427.1594\n",
      "1000/1000 [==============================] - 430s 430ms/step - loss: 1.7286 - mean q: 2.9036 - rewards: -0.0775 - reward sum: -40650.5388 - l/s: 0.0275 - t: 424.2317\n",
      "1000/1000 [==============================] - 428s 428ms/step - loss: 1.0021 - mean q: 2.8830 - rewards: -0.1247 - reward sum: -41149.4953 - l/s: 0.0345 - t: 425.2259\n",
      "1000/1000 [==============================] - 428s 428ms/step - loss: 0.7817 - mean q: 2.8782 - rewards: -0.1396 - reward sum: -41707.7053 - l/s: -0.0190 - t: 471.1550\n",
      "1000/1000 [==============================] - 475s 475ms/step - loss: 0.7164 - mean q: 2.8459 - rewards: -0.0862 - reward sum: -42052.6495 - l/s: 0.0105 - t: 470.2978\n",
      "1000/1000 [==============================] - 471s 471ms/step - loss: 0.5942 - mean q: 2.8304 - rewards: -0.0934 - reward sum: -42426.1034 - l/s: 0.0105 - t: 465.1567\n",
      "  72/1000 [=>............................] - ETA: 7:41 - loss: 2.3265 - mean q: 2.9626 - rewards: -0.1493 - reward sum: -42469.1060 - l/s: -0.0623 - t: 573.6394"
     ]
    }
   ],
   "source": [
    "x = [environment() for _ in range(train_parallel)]\n",
    "print(\"training...\")\n",
    "n = 1000000000\n",
    "agent.train(num_steps = n, envs = x, warmup = 0, log_interval = 1000, train_steps_per_step=1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99668af5-9022-416d-9a39-46886ff14463",
   "metadata": {},
   "outputs": [],
   "source": [
    "rew = [i[2] for i in agent.memory]\n",
    "sorted(rew)[0:10], sorted(rew)[-10:][::-1], \" - \", np.mean([abs(i) for i in rew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a23302-fdb4-45f5-a315-6cc784c94461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ba604-8d37-4c7c-957c-74e333f91a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8225cbed-9425-4cf1-af1b-9b23242d418f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "autoscrollcelloutput": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
