{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82e9e33-f164-4cc3-87ff-f79d5818fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"   \n",
    "import MetaTrader5 as mt5\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342ed7b3-0444-42f1-9517-d406aef35a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_offset = 8 # time - hour_offset = ny local time\n",
    "mt5.initialize()\n",
    "authorized=mt5.login(25031341, password = \"!geH2e4Pi!Ka\", server = \"TickmillUK-Demo\")\n",
    "mt5.account_info()\n",
    "dlen = 120\n",
    "res_high = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31721655-8589-407b-a1a8-f351854246fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class candle_class:\n",
    "    def __init__(self, o=0,h=0,l=0,c=0,t=0):\n",
    "        self.o=o\n",
    "        self.h=h\n",
    "        self.l=l\n",
    "        self.c=c\n",
    "        self.t=t\n",
    "        \n",
    "def get_prices(symbol, tf, lookback):\n",
    "    t = int(time.time()) + 60*60*24\n",
    "\n",
    "    prices = mt5.copy_rates_from(symbol, tf, t, lookback)\n",
    "    \n",
    "    candles = []\n",
    "    for t,o,h,l,c,_,_,_ in prices:\n",
    "        t = datetime.fromtimestamp(int(t)) - timedelta (hours=hour_offset)\n",
    "        t = str(t.hour)+\":\"+str(t.minute)\n",
    "        x = candle_class()\n",
    "        x.h=h\n",
    "        x.l=l\n",
    "        x.o=o\n",
    "        x.c=c\n",
    "        x.t=t\n",
    "        candles.append(x)\n",
    "    \n",
    "    \n",
    "    return candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f391391-8427-4b6a-a3ac-a2d6a4879bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f01be28-5d46-49b8-a507-618fc359fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeframe_manager:\n",
    "    def __init__(self, candles):\n",
    "        self.candles = candles\n",
    "        self.current_index = 0\n",
    "            \n",
    "        self.d1_candles = deque(maxlen = dlen)\n",
    "        self.h4_candles = deque(maxlen = dlen)\n",
    "        self.h1_candles = deque(maxlen = dlen)\n",
    "        self.m15_candles = deque(maxlen = dlen)\n",
    "    \n",
    "    def get_next_sample_candles(self):\n",
    "        if len(self.candles) == self.current_index:\n",
    "            return -1, -1, -1, -1\n",
    "        while True:\n",
    "            # return dlen candles of d1, h4, h1 and m15\n",
    "            current_candle = self.candles[self.current_index]\n",
    "            current_hour = int(current_candle.t.split(\":\")[0])\n",
    "            current_closing_minute = int(current_candle.t.split(\":\")[1])\n",
    "\n",
    "            # m15 candles:\n",
    "            open_minute = int(current_closing_minute / 15) * 15 # candle saved the last minute but opening minute is better to use\n",
    "            self.m15_candles.append(candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour) +\":\"+str(open_minute)))\n",
    "\n",
    "            # h1 candles:\n",
    "            if  open_minute == 0: # a new hour candle started\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h1_candles) > 0:\n",
    "                    self.h1_candles[-1].c = current_candle.c\n",
    "                    self.h1_candles[-1].h = max(current_candle.h, self.h1_candles[-1].h)\n",
    "                    self.h1_candles[-1].l = min(current_candle.l, self.h1_candles[-1].l)\n",
    "\n",
    "            # h4 candles:\n",
    "            # create a new h4 candle when hour is 17, 21, 1, 5, 9, 13\n",
    "            if  (current_hour == 17 or current_hour == 21 or current_hour == 1 or current_hour == 5 or current_hour == 9 or current_hour == 13) and open_minute == 0:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h4_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h4_candles) > 0:\n",
    "                    self.h4_candles[-1].c = current_candle.c\n",
    "                    self.h4_candles[-1].h = max(current_candle.h, self.h4_candles[-1].h)\n",
    "                    self.h4_candles[-1].l = min(current_candle.l, self.h4_candles[-1].l)\n",
    "\n",
    "            # d1 candles:\n",
    "            # create a new d1 candle when hour is 17\n",
    "            if  current_hour == 17 and open_minute == 0:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.d1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.d1_candles) > 0:\n",
    "                    self.d1_candles[-1].c = current_candle.c\n",
    "                    self.d1_candles[-1].h = max(current_candle.h, self.d1_candles[-1].h)\n",
    "                    self.d1_candles[-1].l = min(current_candle.l, self.d1_candles[-1].l)\n",
    "\n",
    "            self.current_index+=1    \n",
    "            if len(self.d1_candles) == dlen:\n",
    "                break\n",
    "\n",
    "        return self.m15_candles,  self.h1_candles, self.h4_candles, self.d1_candles\n",
    "    \n",
    "    \n",
    "    def to_model_input(self, candles):\n",
    "        def scale_p(p):\n",
    "            return int((p - max_l) / hlrange * (res_high))\n",
    "        max_h = 0\n",
    "        max_l = 1000000\n",
    "        for i in candles:\n",
    "            if i.h > max_h:\n",
    "                max_h = i.h\n",
    "            if i.l < max_l:\n",
    "                max_l = i.l\n",
    "        hlrange = max_h - max_l\n",
    "        \n",
    "        \n",
    "        def scale_time(t):\n",
    "            hour = int(t.split(\":\")[0])\n",
    "            minute = int(t.split(\":\")[1])\n",
    "            total = hour * 60 + minute\n",
    "            max_t = 24*60\n",
    "            scaled = total / max_t\n",
    "            return scaled\n",
    "            \n",
    "        \n",
    "        \n",
    "        image = []\n",
    "        for i in candles:\n",
    "            clm = np.zeros(shape = (res_high+1))\n",
    "            color = 1 if i.o<i.c else -1\n",
    "            high_scaled = scale_p(i.h)\n",
    "            low_scaled = scale_p(i.l)\n",
    "            clm[low_scaled:high_scaled] = 0.5 * color\n",
    "            open_scaled = scale_p(i.o)\n",
    "            close_scaled = scale_p(i.c)\n",
    "            if color == 1:\n",
    "                clm[open_scaled:close_scaled+1] = color\n",
    "            if color == -1:\n",
    "                clm[close_scaled:open_scaled+1] = color\n",
    "                \n",
    "            c_time = scale_time(i.t)\n",
    "            clm[-1] = c_time\n",
    "            image.append(clm)\n",
    "        \n",
    "        current_close = candles[-1].c\n",
    "        scaled_close = scale_p(current_close)\n",
    "        clm = np.zeros(shape = (res_high+1))\n",
    "        clm[scaled_close] = 1\n",
    "        image.append(clm)\n",
    "        \n",
    "        return np.array(image).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286cf6f-07e2-4435-a92c-d9c125e69a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8995db5-01b4-4fb7-bc76-84bec09a1631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa77982-35b1-4061-a196-9849361789b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32233027-5851-49ec-ae85-b6f7d256b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.05, **kwargs):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(TransformerBlock, self).get_config()\n",
    "        base_config['embed_dim'] = self.embed_dim\n",
    "        base_config['num_heads'] = self.num_heads\n",
    "        base_config['ff_dim'] = self.ff_dim\n",
    "        base_config['rate'] = self.rate\n",
    "        return base_config\n",
    "    \n",
    "    \n",
    "    \n",
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim, **kwargs):\n",
    "        self.maxlen = maxlen\n",
    "        self.embed_dim = embed_dim\n",
    "        super(PositionEmbedding, self).__init__(**kwargs)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = self.maxlen\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(PositionEmbedding, self).get_config()\n",
    "        base_config['maxlen'] = self.maxlen\n",
    "        base_config['embed_dim'] = self.embed_dim\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83f9c3ef-268a-4674-b69e-918004735e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 101, 121)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 100, 121)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 100, 121)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_4 (Sli (None, 100, 121)     0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_6 (Sli (None, 100, 121)     0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 100, 121, 1)  0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 100, 121, 1)  0           tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 100, 121, 1)  0           tf.__operators__.getitem_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 100, 121, 1)  0           tf.__operators__.getitem_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 100, 121, 64) 5248        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 100, 121, 64) 5248        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 100, 121, 64) 5248        reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 100, 121, 64) 5248        reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 100, 121, 65) 0           reshape[0][0]                    \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100, 121, 65) 0           reshape_3[0][0]                  \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 100, 121, 65) 0           reshape_6[0][0]                  \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 100, 121, 65) 0           reshape_9[0][0]                  \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100, 121, 64) 4224        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 100, 121, 64) 4224        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 100, 121, 64) 4224        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 100, 121, 64) 4224        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (None, 121, 100, 64) 0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 121)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_1 (TFOpL (None, 121, 100, 64) 0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (None, 121)          0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_2 (TFOpL (None, 121, 100, 64) 0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_5 (Sli (None, 121)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_3 (TFOpL (None, 121, 100, 64) 0           dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_7 (Sli (None, 121)          0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 121, 6400)    0           tf.compat.v1.transpose[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 121, 1)       0           tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 121, 6400)    0           tf.compat.v1.transpose_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 121, 1)       0           tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 121, 6400)    0           tf.compat.v1.transpose_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 121, 1)       0           tf.__operators__.getitem_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 121, 6400)    0           tf.compat.v1.transpose_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 121, 1)       0           tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 121, 6401)    0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 121, 6401)    0           reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 121, 6401)    0           reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 121, 6401)    0           reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 121, 512)     3277824     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 121, 512)     3277824     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 121, 512)     3277824     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 121, 512)     3277824     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 121, 512)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 121, 512)     0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 121, 512)     0           dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 121, 512)     0           dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 121, 512)     262656      leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 121, 512)     262656      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 121, 512)     262656      leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 121, 512)     262656      leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 121, 512)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 121, 512)     0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 121, 512)     0           dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 121, 512)     0           dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 121, 96)      49248       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 121, 96)      49248       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 121, 96)      49248       leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 121, 96)      49248       leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 121, 96)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 121, 96)      0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 121, 96)      0           dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 121, 96)      0           dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 121, 96)      192         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 121, 96)      192         leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, 121, 96)      192         leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_21 (LayerNo (None, 121, 96)      192         leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding (PositionEmb (None, 121, 96)      11616       layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding_1 (PositionE (None, 121, 96)      11616       layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding_2 (PositionE (None, 121, 96)      11616       layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding_3 (PositionE (None, 121, 96)      11616       layer_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block (TransformerB (None, 121, 96)      347200      position_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_3 (Transforme (None, 121, 96)      347200      position_embedding_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_6 (Transforme (None, 121, 96)      347200      position_embedding_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_9 (Transforme (None, 121, 96)      347200      position_embedding_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_1 (Transforme (None, 121, 96)      347200      transformer_block[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_4 (Transforme (None, 121, 96)      347200      transformer_block_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_7 (Transforme (None, 121, 96)      347200      transformer_block_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_10 (Transform (None, 121, 96)      347200      transformer_block_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_2 (Transforme (None, 121, 96)      347200      transformer_block_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_5 (Transforme (None, 121, 96)      347200      transformer_block_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_8 (Transforme (None, 121, 96)      347200      transformer_block_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_11 (Transform (None, 121, 96)      347200      transformer_block_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 121, 512)     49664       transformer_block_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 121, 512)     49664       transformer_block_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 121, 512)     49664       transformer_block_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 121, 512)     49664       transformer_block_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 121, 512)     0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 121, 512)     0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 121, 512)     0           dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 121, 512)     0           dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 121, 512)     262656      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 121, 512)     262656      leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 121, 512)     262656      leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 121, 512)     262656      leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 121, 512)     0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 121, 512)     0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 121, 512)     0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 121, 512)     0           dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 256)          591360      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 256)          591360      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 256)          591360      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 256)          591360      leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         263168      gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1024)         263168      gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 1024)         263168      gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 1024)         263168      gru_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 1024)         0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 1024)         0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 1024)         0           dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 1024)         0           dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1024)         1049600     leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 1024)         1049600     leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 1024)         1049600     leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 1024)         1049600     leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 1024)         0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 1024)         0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 1024)         0           dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 1024)         0           dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1024)         1049600     leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1024)         1049600     leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 1024)         1049600     leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 1024)         1049600     leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 1024)         0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 1024)         0           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 1024)         0           dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 1024)         0           dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 256)          262400      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 256)          262400      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 256)          262400      leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 256)          262400      leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 256)          0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 256)          0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 256)          0           dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1025)         0           leaky_re_lu_8[0][0]              \n",
      "                                                                 leaky_re_lu_17[0][0]             \n",
      "                                                                 leaky_re_lu_26[0][0]             \n",
      "                                                                 leaky_re_lu_35[0][0]             \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 1024)         1050624     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 1024)         0           dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 1024)         1049600     leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 1024)         0           dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 1024)         1049600     leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 1024)         0           dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 2)            2048        leaky_re_lu_38[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 35,876,096\n",
      "Trainable params: 35,876,096\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def proc_chart(x):\n",
    "    #x1 = image\n",
    "    #x2 = time\n",
    "    x1 = x[::, :-1, :]\n",
    "    x2 = x[::,-1,:]\n",
    "\n",
    "    x1 = tf.keras.layers.Reshape((res_high, dlen+1, 1))(x1)\n",
    "    \n",
    "    x5 = tf.keras.layers.Conv2D(64, 9,activation=\"relu\", padding=\"same\")(x1)\n",
    "    x1 = tf.keras.layers.Concatenate()([x1,x5])\n",
    "    x1 = tf.keras.layers.Dense(64)(x1)\n",
    "    \n",
    "    x1 = tf.transpose(x1,perm=[0, 2, 1, 3])\n",
    "    x1 = tf.keras.layers.Reshape((dlen+1, res_high*x1.shape[-1]))(x1)\n",
    "    x2 = tf.keras.layers.Reshape((dlen+1, 1))(x2)\n",
    "    x1 = tf.keras.layers.Concatenate()([x1,x2])\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(512)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(512)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(96)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    \n",
    "    \n",
    "    x1 = PositionEmbedding(dlen+1, x1.shape[-1])(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "\n",
    "    x1 = tf.keras.layers.Dense(512)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(512)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    #x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x1 = tf.keras.layers.GRU(256)(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(1024,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(256,activity_regularizer=tf.keras.regularizers.L2(0.00001))(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    #x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    return x1\n",
    "    \n",
    "if True:\n",
    "    input_m15 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h4 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_d1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    \n",
    "    x1 = proc_chart(input_m15)\n",
    "    x2 = proc_chart(input_h1)\n",
    "    x3 = proc_chart(input_h4)\n",
    "    x4 = proc_chart(input_d1)\n",
    "    \n",
    "    input_net_position = tf.keras.layers.Input(shape = (1))\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Concatenate()([x1,x2,x3,x4,input_net_position])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(2, activation = \"linear\", use_bias=False, dtype=\"float32\")(x)\n",
    "    model = tf.keras.Model([input_m15,input_h1,input_h4, input_d1, input_net_position], outputs)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b80e8aa-283a-44c9-a847-57cfffe50a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_candles = deque(maxlen = dlen)\n",
    "def plot_candles(candles, name, plot_entrys = False, was_entry = 0):\n",
    "    global entry_candles\n",
    "    if plot_entrys:\n",
    "        if was_entry != 0:\n",
    "            entry_candles.append([0,was_entry])\n",
    "            \n",
    "    \n",
    "    def scale_p(p):\n",
    "        return (p - max_l) / hlrange * h\n",
    "    \n",
    "    w = 300\n",
    "    h = 200\n",
    "    canvas = np.zeros((h,w,3), np.uint8) \n",
    "    l = dlen\n",
    "    single_candle_w = w / l * 0.95\n",
    "    max_h = 0\n",
    "    max_l = 1000000\n",
    "    for i in candles:\n",
    "        if i.h > max_h:\n",
    "            max_h = i.h\n",
    "        if i.l < max_l:\n",
    "            max_l = i.l\n",
    "    hlrange = max_h - max_l\n",
    "    \n",
    "    for i in range(len(candles)):  \n",
    "        color = (0,200,0) if candles[i].c > candles[i].o else (0,0,200)\n",
    "        if plot_entrys:\n",
    "            color = (0,100,0) if candles[i].c > candles[i].o else (0,0,100)\n",
    "        cv2.rectangle(canvas, (int(i*single_candle_w),int(scale_p(candles[i].o))), (int((i+1)*single_candle_w),int(scale_p(candles[i].c))), color, -1)\n",
    "        cv2.line(canvas, (int((i+0.5)*single_candle_w),int(scale_p(candles[i].h))), (int((i+0.5)*single_candle_w),int(scale_p(candles[i].l))), color)\n",
    "\n",
    "    if plot_entrys:\n",
    "        for i in range(len(entry_candles)):\n",
    "            entry_candles[i][0]+=1\n",
    "            \n",
    "        if len(entry_candles) > 1 and len(candles) == dlen:\n",
    "            for i in range(len(entry_candles)-1):\n",
    "                entry = entry_candles[i][0]\n",
    "                exit = entry_candles[i+1][0]\n",
    "                position = entry_candles[i][1]\n",
    "                if position == 2:continue\n",
    "                startpos = dlen - entry\n",
    "                endpos = dlen - exit\n",
    "                if startpos > 0:\n",
    "                    color = (0,255,0) if position == 1 else (0,0,255)\n",
    "                    #print(startpos, endpos)\n",
    "                    cv2.line(canvas, (int((startpos+0.5)*single_candle_w),int(scale_p(candles[startpos].c))), (int((endpos+0.5)*single_candle_w),int(scale_p(candles[endpos].c))), color, 2)\n",
    "            \n",
    "        \n",
    "        \n",
    "    canvas = canvas[::-1]\n",
    "    \n",
    "    cv2.imshow(name, canvas)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    \n",
    "def plot_outputs(outputs):\n",
    "    \n",
    "    def scale_p(p):\n",
    "        return (p - max_l) / hlrange * h\n",
    "    \n",
    "    w = 300\n",
    "    h = 200\n",
    "    canvas = np.zeros((h,w,3), np.uint8) \n",
    "    l = dlen\n",
    "    single_candle_w = w / l * 0.95\n",
    "    max_h = 0\n",
    "    max_l = 1000000\n",
    "    for i in outputs:\n",
    "        if max(i) > max_h:\n",
    "            max_h = max(i)\n",
    "        if min(i) < max_l:\n",
    "            max_l = min(i)\n",
    "    hlrange = max_h - max_l\n",
    "    \n",
    "    for i in range(len(outputs)-1):  \n",
    "        cv2.line(canvas, (int((i+0.5)*single_candle_w),int(scale_p(outputs[i][1]))), (int((i+1+0.5)*single_candle_w),int(scale_p(outputs[i+1][1]))), (0,200,0))\n",
    "        cv2.line(canvas, (int((i+0.5)*single_candle_w),int(scale_p(outputs[i][0]))), (int((i+1+0.5)*single_candle_w),int(scale_p(outputs[i+1][0]))), (0,0,200))\n",
    "\n",
    "    canvas = canvas[::-1]\n",
    "    \n",
    "    cv2.imshow(\"outputs\", canvas)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "def plot_eq(eq_list):\n",
    "    if len(eq_list) < 5:\n",
    "        return\n",
    "    def scale_p(p):\n",
    "        return int((p - max_l) / hlrange * h)\n",
    "    \n",
    "    w = 500\n",
    "    h = 200\n",
    "    canvas = np.zeros((h,w,3), np.uint8) \n",
    "    l = dlen\n",
    "    single_candle_w = w / l * 0.95\n",
    "    max_h = max(eq_list)\n",
    "    max_l = min(eq_list)\n",
    "    \n",
    "    hlrange = max_h - max_l\n",
    "    if hlrange == 0:\n",
    "        return\n",
    "    \n",
    "    m = w\n",
    "    nc = len(eq_list) / m\n",
    "    i = 0\n",
    "    num = 0\n",
    "    while True:\n",
    "        pos0 = eq_list[int(i)]\n",
    "        pos1 = eq_list[int(i+nc)]\n",
    "        cv2.line(canvas, (num, scale_p(pos0)), (num+1, scale_p(pos1)),(200,200,200))\n",
    "        i+=nc\n",
    "        num+=1\n",
    "        if num+1 == m:\n",
    "            break\n",
    "            \n",
    "    canvas = canvas[::-1]\n",
    "    cv2.imshow(\"equity\", canvas)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5c5008-d4f2-4d38-8559-c0b37729f8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18554f9ea90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "candles = get_prices(\"EURUSD\", mt5.TIMEFRAME_M15, 80000)\n",
    "tm = timeframe_manager(candles)\n",
    "m15,h1,h4,d1 = tm.get_next_sample_candles()\n",
    "plt.imshow(tm.to_model_input(m15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232b65bc-5d6b-46b1-9322-f390cb940412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.4138  .  -1   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b3741353a0d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mh4i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_model_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres_high\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdlen\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0md1i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_model_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres_high\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdlen\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm15i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh1i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh4i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md1i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 415\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-5bbc3c01a4a9>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mout1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayernorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\normalization\\layer_normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m       \u001b[1;31m# Calculate the moments on the last axis (layer activations).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m       \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m       \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36mmoments_v2\u001b[1;34m(x, axes, shift, keepdims, name)\u001b[0m\n\u001b[0;32m   1395\u001b[0m     \u001b[0mTwo\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m   \"\"\"\n\u001b[1;32m-> 1397\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mmoments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36mmoments\u001b[1;34m(x, axes, shift, name, keep_dims, keepdims)\u001b[0m\n\u001b[0;32m   1341\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;31m# Compute true mean while keeping the dims for proper broadcasting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1343\u001b[1;33m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1344\u001b[0m     \u001b[1;31m# sample variance, not unbiased variance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1345\u001b[0m     \u001b[1;31m# Note: stop_gradient does not change the gradient that gets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_mean\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2581\u001b[0m       gen_math_ops.mean(\n\u001b[0;32m   2582\u001b[0m           \u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2583\u001b[1;33m           name=name))\n\u001b[0m\u001b[0;32m   2584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[0;32m   5943\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5944\u001b[0m       return mean_eager_fallback(\n\u001b[1;32m-> 5945\u001b[1;33m           input, axis, keep_dims=keep_dims, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m   5946\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5947\u001b[0m       \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmean_eager_fallback\u001b[1;34m(input, axis, keep_dims, name, ctx)\u001b[0m\n\u001b[0;32m   5975\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"keep_dims\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"T\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tidx\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_Tidx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5976\u001b[0m   _result = _execute.execute(b\"Mean\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[1;32m-> 5977\u001b[1;33m                              ctx=ctx, name=name)\n\u001b[0m\u001b[0;32m   5978\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5979\u001b[0m     _execute.record_gradient(\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pos_size = 0.05 * 100000\n",
    "comm = 15/100000\n",
    "#comm = 0/100000\n",
    "model.load_weights(\"dqn_trading_transformer_small.h5\")\n",
    "\n",
    "tm = timeframe_manager(candles)\n",
    "current_position = 0\n",
    "balance = 0\n",
    "equity = 0\n",
    "reset_entry_price = False\n",
    "entry_price = 1\n",
    "\n",
    "eq_list = []\n",
    "outputs = deque(maxlen = dlen)\n",
    "#if True:\n",
    "try:\n",
    "    #while True:\n",
    "    for _ in range(100):\n",
    "    #for _ in range(5000):\n",
    "        m15,h1,h4,d1 = tm.get_next_sample_candles()\n",
    "        if m15 == -1:\n",
    "            break\n",
    "\n",
    "        if reset_entry_price: entry_price = m15[-1].o\n",
    "        current_close = m15[-1].c\n",
    "        percent_change = (current_close - entry_price) / entry_price\n",
    "\n",
    "\n",
    "        equity = balance + percent_change * pos_size * current_position\n",
    "        eq_list.append(equity)\n",
    "\n",
    "        m15i = np.array(tm.to_model_input(m15)).reshape(1,res_high+1,dlen+1)\n",
    "        h1i = np.array(tm.to_model_input(h1)).reshape(1,res_high+1,dlen+1)\n",
    "        h4i = np.array(tm.to_model_input(h4)).reshape(1,res_high+1,dlen+1)\n",
    "        d1i = np.array(tm.to_model_input(d1)).reshape(1,res_high+1,dlen+1)\n",
    "        output = model([m15i, h1i, h4i, d1i, np.array(current_position).reshape(1,1)]).numpy()\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        names = [\"transformer_block\",\"transformer_block_1\",\"transformer_block_2\"]\n",
    "        for name in names:\n",
    "            for i in model.layers[10:]:\n",
    "                if i.name == name:\n",
    "                    m = tf.keras.Model(inputs = model.inputs, outputs = i.output)\n",
    "                    out = m([m15i, h1i, h4i, d1i, np.array(current_position).reshape(1,1)])\n",
    "                    #print(out.shape)\n",
    "                    out = out[0].numpy()\n",
    "                    mi = np.min(out)\n",
    "                    ma = np.max(out)\n",
    "                    out = (out - mi)/(ma-mi)\n",
    "                    cv2.imshow(name, out)\n",
    "        \n",
    "\n",
    "\n",
    "        outputs.append(output[0])\n",
    "\n",
    "        action = np.argmax(output)\n",
    "        was_entry = 0\n",
    "        reset_entry_price = False\n",
    "        if int(m15[-1].t.split(\":\")[0]) >= 16 and int(m15[-1].t.split(\":\")[0]) < 19:\n",
    "            if current_position != 0:\n",
    "                was_entry = 2\n",
    "                current_position = 0\n",
    "                balance = equity\n",
    "        else:\n",
    "            if action == 1: # long\n",
    "                if current_position != 1:\n",
    "                    balance = equity\n",
    "                    current_position = 1\n",
    "                    balance -= pos_size * comm\n",
    "                    reset_entry_price = True\n",
    "                    was_entry = 1\n",
    "                    #print(\"long\")\n",
    "\n",
    "            if action == 0: # short\n",
    "                if current_position != -1:\n",
    "                    balance = equity\n",
    "                    current_position = -1\n",
    "                    balance -= pos_size * comm\n",
    "                    reset_entry_price = True\n",
    "                    was_entry = -1\n",
    "                    #print(\"short\")\n",
    "\n",
    "\n",
    "        plot_eq(eq_list)\n",
    "        plot_candles(m15,\"m15\", True, was_entry)\n",
    "        plot_candles(h1,\"h1\")\n",
    "        plot_candles(h4,\"h4\")\n",
    "        plot_candles(d1,\"d1\")\n",
    "        plot_outputs(outputs)\n",
    "        print(\"\\r\", round(equity,5), \" . \", current_position, end = \"  \")\n",
    "        \n",
    "        \n",
    "        #break\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "cv2.destroyAllWindows()\n",
    "plt.plot(outputs)\n",
    "plt.show()\n",
    "plt.plot(eq_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a376e-b9f6-41c6-b242-8dd1a883fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [m15i, h1i, h4i, d1i, np.array(current_position).reshape(1,1)]\n",
    "\n",
    "names = [\"transformer_block\",\"transformer_block_1\",\"transformer_block_2\"]\n",
    "for name in names:\n",
    "    for i in model.layers[10:]:\n",
    "        if i.name == name:\n",
    "            print(\"#\")\n",
    "            m = tf.keras.Model(inputs = model.inputs, outputs = i.output)\n",
    "            out = m(inp)\n",
    "\n",
    "    for i in range(96):\n",
    "        plt.plot(np.array(out[0]).T[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc88e69-7c06-456b-9bba-b9f5142d1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [m15i, h1i, h4i, d1i, np.array(current_position).reshape(1,1)]\n",
    "\n",
    "for i in model.layers[10:]:\n",
    "    if (\"conv\" in i.name or \"dense\" in i.name or \"posi\" in i.name or \"transfo\" in i.name or \"norm\" in i.name or \"gru\" in i.name):\n",
    "    #if (\"dense\" in i.name or \"transfo\" in i.name or \"norm\" in i.name or \"gru\" in i.name):\n",
    "        m = tf.keras.Model(inputs = model.inputs, outputs = i.output)\n",
    "        out = m(inp)[0]\n",
    "        print(i.name, i.output.shape, np.max(out), np.min(out))\n",
    "        if len(out.shape) == 3:\n",
    "            c = out.shape[-1]\n",
    "            h = int(c/16)\n",
    "            if c%16 !=0:\n",
    "                h += 1\n",
    "            fig, ax = plt.subplots(h,16, figsize = (20,5))\n",
    "            for o in range(c):\n",
    "                im= out[:,:,o]\n",
    "                ind1 = int(o/16)\n",
    "                ind2 = o%16\n",
    "                ax[ind1,ind2].imshow(cv2.resize(im.numpy(), (100,100)), cmap = \"gray\")\n",
    "            plt.show()\n",
    "        elif len (out.shape) == 1:\n",
    "            plt.scatter([x for x in range(len(out))],out)\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.imshow(out, cmap = \"gray\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf91055-9497-46b2-9db5-f9d34e0ddcba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b513da8-4bc1-4ca0-af1a-5a2b7def2f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a85634-0cd4-4a7c-b3a0-83821d196044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d15dc5-01b5-4a95-9742-75a352f5eae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aafe32-5751-411a-bc8e-f418747af0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cdc784-349c-45fe-98a3-d0bd4ef8598c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67836d1c-e003-4196-9446-4b5237da9bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4e326-6941-4765-bdb8-4aaa1a7c612b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c067ba1-394b-480b-afc9-28029d57ed85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
