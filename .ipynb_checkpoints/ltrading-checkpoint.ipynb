{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c30e6f3-94f2-4fcf-9793-821d75d1f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd    \n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import clear_output\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2\n",
    "import pickle\n",
    "dlen = 120\n",
    "pos_size = 0.05 * 100000\n",
    "comm = 15/100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4732a-2b79-46e1-8c1b-3c2529f07c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d3d383-8ea7-4323-8a9f-0f78a9ec0da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa1857a-99cd-4633-a6fb-0616a475f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load(file):\n",
    "    f = open(file, \"rb\")\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72913f11-cf58-41b8-bcf5-34293e18b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class candle_class:\n",
    "    def __init__(self, o,h,l,c,t):\n",
    "        self.o=o\n",
    "        self.h=h\n",
    "        self.l=l\n",
    "        self.c=c\n",
    "        self.t=t\n",
    "\n",
    "class environment:\n",
    "    def __init__(self):\n",
    "        self.data_dir = \"./archive\"\n",
    "        #print(self.files)\n",
    "        #self.reset()\n",
    "\n",
    "    def reset(self, first = False):\n",
    "        self.files = [self.data_dir+\"/\"+x for x in os.listdir(self.data_dir) if \"candle_classes\" in x]\n",
    "        p = random.choice(self.files)\n",
    "        print(\"using\",p)\n",
    "        self.candles = Load(p)\n",
    "        #print(self.candles)\n",
    "        \n",
    "        \n",
    "        self.current_index = 0\n",
    "        if first:\n",
    "            self.current_index = random.randint(0,len(self.candles)-50000)\n",
    "            \n",
    "        self.d1_candles = deque(maxlen = dlen)\n",
    "        self.h4_candles = deque(maxlen = dlen)\n",
    "        self.h1_candles = deque(maxlen = dlen)\n",
    "        self.m15_candles = deque(maxlen = dlen)\n",
    "        \n",
    "        self.position = 0\n",
    "        self.entry_price = 0\n",
    "        self.equity = 0\n",
    "        self.current_equity = 0\n",
    "        self.balance = 0\n",
    "        \n",
    "            \n",
    "        self.get_sample_candles()\n",
    "        return [self.scale_candles(self.m15_candles), self.scale_candles(self.h1_candles), self.scale_candles(self.h4_candles), self.scale_candles(self.d1_candles), self.position]\n",
    "            \n",
    "    def close(self):\n",
    "        if self.position !=0:\n",
    "            self.balance = self.equity\n",
    "            self.position = 0\n",
    "        \n",
    "    def step(self, action) :\n",
    "        last_equity = self.equity\n",
    "        reset_entry_price = False\n",
    "        if action == 1: # long\n",
    "            if self.position != 1:\n",
    "                self.close()\n",
    "                self.position = 1\n",
    "                self.balance -= pos_size * comm\n",
    "                reset_entry_price = True\n",
    "                \n",
    "        if action == 0: # short\n",
    "            if self.position != -1:\n",
    "                self.close()\n",
    "                self.position = -1\n",
    "                self.balance -= pos_size * comm\n",
    "                reset_entry_price = True\n",
    "        \n",
    "        \n",
    "        if self.get_sample_candles() == -1:\n",
    "            print(\"error\")\n",
    "            return -1\n",
    "            \n",
    "        current_close = self.m15_candles[-1].c\n",
    "        if reset_entry_price: self.entry_price = self.m15_candles[-1].o\n",
    "        \n",
    "        percent_change = (current_close - self.entry_price) / self.entry_price\n",
    "\n",
    "        self.equity = self.balance + percent_change * pos_size * self.position\n",
    "        \n",
    "        reward = self.equity - last_equity\n",
    "        next_observation = [self.scale_candles(self.m15_candles), self.scale_candles(self.h1_candles), self.scale_candles(self.h4_candles), self.scale_candles(self.d1_candles), self.position]\n",
    "            \n",
    "        return next_observation, reward, len(self.candles) == self.current_index\n",
    "        \n",
    "        \n",
    "    def get_sample_candles(self):\n",
    "        if len(self.candles) == self.current_index:\n",
    "            return -1\n",
    "        while True:\n",
    "            # return dlen candles of d1, h4, h1 and m15\n",
    "            current_candle = self.candles[self.current_index]\n",
    "            current_hour = int(current_candle.t.split(\":\")[0])\n",
    "            current_closing_minute = int(current_candle.t.split(\":\")[1])\n",
    "\n",
    "            # m15 candles:\n",
    "            open_minute = int(current_closing_minute / 15) * 15 # candle saved the last minute but opening minute is better to use\n",
    "            self.m15_candles.append(candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour) +\":\"+str(open_minute)))\n",
    "\n",
    "            # h1 candles:\n",
    "            if  open_minute == 0: # a new hour candle started\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h1_candles) > 0:\n",
    "                    self.h1_candles[-1].c = current_candle.c\n",
    "                    self.h1_candles[-1].h = max(current_candle.h, self.h1_candles[-1].h)\n",
    "                    self.h1_candles[-1].l = min(current_candle.l, self.h1_candles[-1].l)\n",
    "\n",
    "            # h4 candles:\n",
    "            # create a new h4 candle when hour is 17, 21, 1, 5, 9, 13\n",
    "            if  current_hour == 17 or current_hour == 21 or current_hour == 1 or current_hour == 5 or current_hour == 9 or current_hour == 13:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h4_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h4_candles) > 0:\n",
    "                    self.h4_candles[-1].c = current_candle.c\n",
    "                    self.h4_candles[-1].h = max(current_candle.h, self.h4_candles[-1].h)\n",
    "                    self.h4_candles[-1].l = min(current_candle.l, self.h4_candles[-1].l)\n",
    "\n",
    "            # d1 candles:\n",
    "            # create a new d1 candle when hour is 17\n",
    "            if  current_hour == 17:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.d1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.d1_candles) > 0:\n",
    "                    self.d1_candles[-1].c = current_candle.c\n",
    "                    self.d1_candles[-1].h = max(current_candle.h, self.d1_candles[-1].h)\n",
    "                    self.d1_candles[-1].l = min(current_candle.l, self.d1_candles[-1].l)\n",
    "\n",
    "            self.current_index+=1    \n",
    "            if len(self.d1_candles) == dlen:\n",
    "                break\n",
    "\n",
    "        return self.m15_candles,  self.h1_candles, self.h4_candles, self.d1_candles\n",
    "    \n",
    "    def scale_candles(self, candles):\n",
    "        # scale between -1 and 1\n",
    "        def scale_p(p):\n",
    "            return ((p - max_l) / hlrange * 2) -1\n",
    "        max_h = 0\n",
    "        max_l = 1000000\n",
    "        for i in candles:\n",
    "            if i.h > max_h:\n",
    "                max_h = i.h\n",
    "            if i.l < max_l:\n",
    "                max_l = i.l\n",
    "        hlrange = max_h - max_l\n",
    "        \n",
    "        open_prices = [scale_p(x.o) for x in candles]\n",
    "        high_prices = [scale_p(x.h) for x in candles]\n",
    "        low_prices = [scale_p(x.l) for x in candles]\n",
    "        close_prices = [scale_p(x.c) for x in candles]\n",
    "        \n",
    "        def scale_time(t):\n",
    "            hour = int(t.split(\":\")[0])\n",
    "            minute = int(t.split(\":\")[1])\n",
    "            total = hour * 60 + minute\n",
    "            max_t = 24*60\n",
    "            scaled = total / max_t\n",
    "            return scaled\n",
    "            \n",
    "        times = [scale_time(x.t) for x in candles]\n",
    "        \n",
    "        \n",
    "        return np.array([open_prices, high_prices, low_prices, close_prices, times])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4835645d-95a9-484d-b4d3-04ce14fb2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#states = m15candles, h1candles, h4candles, d1candles, position\n",
    "#states =(5,dlen), (5,dlen), (5,dlen), (5,dlen), (1)\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, model,\n",
    "                 n_actions,\n",
    "                 memory_size = 100000, \n",
    "                 optimizer = tf.keras.optimizers.Adam(0.0005), \n",
    "                 gamma = 0.99,\n",
    "                 batch_size =32,\n",
    "                 name = \"dqn1\",\n",
    "                 target_model_sync = 1000,\n",
    "                 exploration = 0.01\n",
    "                ):\n",
    "        self.exploration = exploration\n",
    "        self.gamma = gamma\n",
    "        self.n_actions = n_actions\n",
    "        self.batch_size = batch_size\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.memory_size = memory_size\n",
    "        self.optimizer = optimizer\n",
    "        self.m1 = np.eye(self.n_actions, dtype=\"float32\")\n",
    "        self.target_model = tf.keras.models.clone_model(self.model)\n",
    "        self.target_model_sync = target_model_sync\n",
    "   \n",
    "        self.memory = deque(maxlen = self.memory_size)\n",
    "      \n",
    "    \n",
    "    def copy_weights(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "      \n",
    "    def load_weights(self):\n",
    "        self.model.load_weights(self.name)\n",
    "    def save_weights(self):\n",
    "        self.model.save_weights(self.name, overwrite = True)\n",
    "        \n",
    "    @tf.function(jit_compile = False)\n",
    "    def model_call(self, x):\n",
    "        x1, x2, x3, x4, x5 = x\n",
    "        return tf.math.argmax(self.model([x1,x2,x3,x4,x5]), axis = 1)\n",
    "    \n",
    "    def select_actions(self, state1, state2, state3, state4, state5):\n",
    "        if np.random.random() < self.exploration: # random action\n",
    "            return [np.random.randint(0,self.n_actions) for _ in range(len(state5))]\n",
    "        \n",
    "        ret = self.model_call([state1, state2, state3, state4, state5])\n",
    "        return ret\n",
    "\n",
    "\n",
    "        \n",
    "    def observe_sasrt(self, state, action, next_state, reward, terminal):\n",
    "        self.memory.append([state, action, reward, 1-int(terminal), next_state])\n",
    "        \n",
    "    @tf.function(jit_compile = False)\n",
    "    def get_target_q(self, next_states, rewards, terminals):\n",
    "        estimated_q_values_next = self.target_model(next_states)\n",
    "        q_batch = tf.math.reduce_max(estimated_q_values_next, axis=1)\n",
    "        target_q_values = q_batch * self.gamma * terminals + rewards\n",
    "        return target_q_values\n",
    "\n",
    "        \n",
    "    #@tf.function(jit_compile = False)\n",
    "    def tstep(self, data):\n",
    "        states, next_states, rewards, terminals, masks = data\n",
    "        target_q_values = self.get_target_q(next_states, rewards, terminals)\n",
    "        \n",
    "        with tf.GradientTape() as t:\n",
    "            model_return = self.model(states, training=True) \n",
    "            mask_return = model_return * masks\n",
    "            estimated_q_values = tf.math.reduce_sum(mask_return, axis=1)\n",
    "            #print(estimated_q_values, mask_return, model_return, masks)\n",
    "            loss_e = tf.math.square(target_q_values - estimated_q_values)\n",
    "            loss = tf.reduce_mean(loss_e)\n",
    "        \n",
    "        \n",
    "        gradient = t.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradient, self.model.trainable_variables))\n",
    "        \n",
    "        return loss, tf.reduce_mean(estimated_q_values)\n",
    "    \n",
    "    \n",
    "    def data_get_func(self):\n",
    "        idx = np.random.randint(0, len(self.memory), self.batch_size)\n",
    "        sarts_batch = [self.memory[i] for i in idx]\n",
    "        \n",
    "        states = [x[0] for x in sarts_batch]\n",
    "        states_1 = np.array([x[0] for x in states], dtype=\"float32\")\n",
    "        states_2 = np.array([x[1] for x in states], dtype=\"float32\")\n",
    "        states_3 = np.array([x[2] for x in states], dtype=\"float32\")\n",
    "        states_4 = np.array([x[3] for x in states], dtype=\"float32\")\n",
    "        states_5 = np.array([x[4] for x in states], dtype=\"float32\")\n",
    "        \n",
    "        actions = [x[1] for x in sarts_batch]\n",
    "        rewards = np.array([x[2] for x in sarts_batch], dtype=\"float32\")\n",
    "        terminals = np.array([x[3] for x in sarts_batch], dtype=\"float32\")\n",
    "        \n",
    "        next_states = [x[4] for x in sarts_batch]\n",
    "        next_states_1 = np.array([x[0] for x in next_states], dtype=\"float32\")\n",
    "        next_states_2 = np.array([x[1] for x in next_states], dtype=\"float32\")\n",
    "        next_states_3 = np.array([x[2] for x in next_states], dtype=\"float32\")\n",
    "        next_states_4 = np.array([x[3] for x in next_states], dtype=\"float32\")\n",
    "        next_states_5 = np.array([x[4] for x in next_states], dtype=\"float32\")\n",
    "        \n",
    "        masks = np.array(self.m1[actions])\n",
    "        return [states_1, states_2, states_3, states_4, states_5], [next_states_1, next_states_2, next_states_3, next_states_4, next_states_5], rewards, terminals, masks\n",
    "\n",
    "    def update_parameters(self):\n",
    "        self.total_steps_trained+=1\n",
    "        if self.total_steps_trained % self.target_model_sync == 0:\n",
    "            self.copy_weights()\n",
    "\n",
    "           \n",
    "        data = self.data_get_func()\n",
    "        result= self.tstep(data)\n",
    "   \n",
    "        return  result\n",
    "    \n",
    "    def train(self, num_steps, envs, log_interval = 1000, warmup = 0, train_steps_per_step = 1):\n",
    "        self.total_steps_trained = -1\n",
    "\n",
    "        num_envs = len(envs)\n",
    "        states = [x.reset(True) for x in envs]\n",
    "        \n",
    "        current_episode_reward_sum = 0\n",
    "        times= deque(maxlen=10)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.longs = 0\n",
    "        self.shorts = 0\n",
    "\n",
    "        self.total_rewards = []\n",
    "        self.losses = [0]\n",
    "        self.q_v = [0]\n",
    "        \n",
    "        def save_current_run():\n",
    "            self.save_weights()\n",
    "            file = open(log_folder+\"logs/loss_log.txt\", \"a\")  \n",
    "            #for loss in self.losses:\n",
    "                        #file.write(str(loss))\n",
    "                        #file.write(\"\\n\")\n",
    "            file.write(str(np.mean(self.losses)))\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "\n",
    "            file = open(log_folder+\"logs/qv_log.txt\", \"a\")  \n",
    "            #for qv in self.q_v:\n",
    "                        #file.write(str(qv))\n",
    "                        #file.write(\"\\n\")\n",
    "            file.write(str(np.mean(self.q_v)))\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "\n",
    "            file = open(log_folder+\"logs/rewards_log.txt\", \"a\")  \n",
    "            #for total_reward in self.total_rewards:\n",
    "                        #file.write(str(total_reward))\n",
    "                        #file.write(\"\\n\")\n",
    "                    \n",
    "            file.write(str(np.mean(self.total_rewards)))\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "            \n",
    "    \n",
    "\n",
    "            self.total_rewards = []\n",
    "            self.losses = [0]\n",
    "            self.q_v = [0]\n",
    "        \n",
    "        try:\n",
    "            for i in range(num_steps):\n",
    "                if i % log_interval == 0:\n",
    "                    progbar = tf.keras.utils.Progbar(log_interval, interval=0.1, stateful_metrics = [\"reward sum\", \"t\", \"l/s\"])\n",
    "                    self.longs = 0\n",
    "                    self.shorts = 0\n",
    "\n",
    "\n",
    "                states_1 = np.array([x[0] for x in states])\n",
    "                states_2 = np.array([x[1] for x in states])\n",
    "                states_3 = np.array([x[2] for x in states])\n",
    "                states_4 = np.array([x[3] for x in states])\n",
    "                states_5 = np.array([x[4] for x in states])\n",
    "                \n",
    "                actions = self.select_actions(states_1, states_2, states_3, states_4, states_5)\n",
    "                for action in actions:\n",
    "                    if action == 0:\n",
    "                        self.shorts+=1\n",
    "                    elif action == 1:\n",
    "                        self.longs+=1\n",
    "\n",
    "                sasrt_pairs = []\n",
    "                for index in range(num_envs):\n",
    "                    sasrt_pairs.append([states[index], actions[index]]+[x for x in envs[index].step(actions[index])])\n",
    "\n",
    "                next_states = [x[2] for x in sasrt_pairs]\n",
    "\n",
    "                reward = [x[3] for x in sasrt_pairs]\n",
    "                current_episode_reward_sum += np.sum(reward)\n",
    "\n",
    "                self.total_rewards.extend(reward)\n",
    "\n",
    "                for index, o in enumerate(sasrt_pairs):\n",
    "                    #print(o)\n",
    "                    if o[4] == True:\n",
    "                        next_states[index] = envs[index].reset()\n",
    "                    self.observe_sasrt(o[0], o[1], o[2], o[3], o[4])\n",
    "\n",
    "                states = next_states\n",
    "                if i > warmup:\n",
    "                    for _ in range(train_steps_per_step):\n",
    "                        loss, q = self.update_parameters()\n",
    "                        self.losses.append(loss.numpy())\n",
    "                        self.q_v.append(q.numpy())\n",
    "                else:\n",
    "                    loss, q = 0, 0\n",
    "\n",
    "                end_time = time.time()\n",
    "                elapsed = (end_time - start_time) * 1000\n",
    "                times.append(elapsed)\n",
    "                start_time = end_time\n",
    "\n",
    "\n",
    "                if (i+1) % log_interval == 0:\n",
    "                    #print(\"-----------\")\n",
    "                    #print(\"l:\", np.mean(self.losses))\n",
    "                    #print(\"q:\", np.mean(self.q_v))\n",
    "                    #print(\"reward sum\", current_episode_reward_sum)\n",
    "                    #print(\"l/s\", (self.longs - self.shorts) / (1+self.longs+self.shorts))\n",
    "                    #print(\"t\", np.mean(times))\n",
    "                    #print(\"-----------\")\n",
    "                    save_current_run()\n",
    "\n",
    "                progbar.update(i%log_interval+1, values = \n",
    "                               [(\"loss\", np.mean(self.losses[-train_steps_per_step:])),\n",
    "                                (\"mean q\", np.mean(self.q_v[-train_steps_per_step:])),\n",
    "                                (\"rewards\", np.mean(reward)),\n",
    "                                (\"reward sum\", current_episode_reward_sum),\n",
    "                                (\"l/s\", (self.longs - self.shorts) / (1+self.longs+self.shorts)),\n",
    "                                (\"t\", np.mean(times))])\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nbreak!\")\n",
    "        \n",
    "        save_current_run()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b701228a-b593-43e5-a4fa-ddf2063b9579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 5, 120)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5, 120)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 5, 120)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 5, 120)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 5, 32)        26912       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 5, 32)        26912       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 5, 32)        26912       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 5, 32)        26912       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 152)       0           conv1d[0][0]                     \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 152)       0           conv1d_1[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 152)       0           conv1d_2[0][0]                   \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 5, 152)       0           conv1d_3[0][0]                   \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5, 64)        9792        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 5, 64)        9792        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 5, 64)        9792        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 5, 64)        9792        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 5, 64)        0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 5, 64)        0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 5, 64)        0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 5, 64)        0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 5, 64)        128         leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 5, 64)        128         leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 5, 64)        128         leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 5, 64)        128         leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 5, 128)       98816       layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 5, 128)       98816       layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 5, 128)       98816       layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 5, 128)       98816       layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 5, 128)       131584      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 5, 128)       131584      lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 5, 128)       131584      lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  (None, 5, 128)       131584      lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 5, 128)       131584      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 5, 128)       131584      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 5, 128)       131584      lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  (None, 5, 128)       131584      lstm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5, 256)       33024       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5, 256)       33024       lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 5, 256)       33024       lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 5, 256)       33024       lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 5, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 5, 256)       0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 5, 256)       0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 5, 256)       0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5, 256)       65792       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 5, 256)       65792       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 5, 256)       65792       leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 5, 256)       65792       leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 5, 256)       0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 5, 256)       0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 5, 256)       0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 5, 256)       0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5, 32)        8224        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 5, 32)        8224        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 5, 32)        8224        leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 5, 32)        8224        leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 5, 32)        0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 5, 32)        0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 5, 32)        0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 5, 32)        0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5, 16)        528         leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 5, 16)        528         leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 5, 16)        528         leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 5, 16)        528         leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 5, 16)        0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 5, 16)        0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 5, 16)        0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 5, 16)        0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 5, 16)        32          leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 5, 16)        32          leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 5, 16)        32          leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 5, 16)        32          leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 80)           0           layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 80)           0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 80)           0           layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 80)           0           layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 321)          0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2048)         659456      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 2048)         0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 2048)         4196352     leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 2048)         0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1024)         2098176     leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 1024)         0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1024)         1049600     leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 1024)         0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 2)            2048        leaky_re_lu_23[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 10,031,296\n",
      "Trainable params: 10,031,296\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def proc_chart(x):\n",
    "    x1 = tf.keras.layers.Conv1D(32, 7,activation=\"relu\", padding=\"same\")(x)\n",
    "    x1 = tf.keras.layers.Concatenate()([x1,x])\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(64)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.LSTM(128,return_sequences = True)(x1)\n",
    "    x1 = tf.keras.layers.LSTM(128,return_sequences = True)(x1)\n",
    "    x1 = tf.keras.layers.LSTM(128,return_sequences = True)(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(256)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(256)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(32)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(16)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    \n",
    "    return x1\n",
    "\n",
    "    \n",
    "if True:\n",
    "    input_m15 = tf.keras.layers.Input(shape = (5, dlen))\n",
    "    input_h1 = tf.keras.layers.Input(shape = (5, dlen))\n",
    "    input_h4 = tf.keras.layers.Input(shape = (5, dlen))\n",
    "    input_d1 = tf.keras.layers.Input(shape = (5, dlen))\n",
    "    \n",
    "    x1 = proc_chart(input_m15)\n",
    "    x2 = proc_chart(input_h1)\n",
    "    x3 = proc_chart(input_h4)\n",
    "    x4 = proc_chart(input_d1)\n",
    "    \n",
    "    input_net_position = tf.keras.layers.Input(shape = (1))\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Concatenate()([x1,x2,x3,x4,input_net_position])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(2048)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dense(2048)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(2, activation = \"linear\", use_bias=False, dtype=\"float32\")(x)\n",
    "    model = tf.keras.Model([input_m15,input_h1,input_h4, input_d1, input_net_position], outputs)\n",
    "    \n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4db0d3e-7df8-4a56-b06c-ea9aeb7a1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "opt = tf.keras.optimizers.Adam(0.00002)\n",
    "\n",
    "name = \"dqn_trading\"\n",
    "log_folder = \"./\"\n",
    "\n",
    "agent = DQNAgent(\n",
    "    model = model, \n",
    "    n_actions = 2, \n",
    "    memory_size = 100000, \n",
    "    gamma=0.95,\n",
    "    optimizer = opt,\n",
    "    batch_size = 512, \n",
    "    target_model_sync = 500,\n",
    "    exploration = 0.02,\n",
    "    name=log_folder+name+\".h5\")\n",
    "\n",
    "if resume:\n",
    "\tprint(\"loading weights...\")\n",
    "\tagent.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411125ec-439f-4de3-bcc3-4e0abf9d3304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 510s 100ms/step - loss: 0.0000e+00 - mean q: 0.0000e+00 - rewards: -0.0458 - reward sum: -2748.6678 - l/s: -0.8460 - t: 88.3581 - loss: 0.0000e+00 - mean q: 0.0000e+00 - rewards: -0.0452 - reward sum: -2701.2768 - l/s: -0.8461 -  - ETA: 0s - loss: 0.0000e+00 - mean q: 0.0000e+00 - rewards: -0.0456 - reward sum: -2731.4929 - l/s: -0.8462 - t: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "x = [environment() for _ in range(12)]\n",
    "print(\"warmup...\")\n",
    "n = 5000\n",
    "agent.train(num_steps = n, envs = x, warmup = n, log_interval = n, train_steps_per_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abb27070-100e-4c75-b51d-3d30d7132ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a81a7b-54d5-4796-b801-0e98ffee8890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "using ./archive/15_AUDUSD.csv_candle_classes\n",
      "using ./archive/15_GBPUSD.csv_candle_classes\n",
      "using ./archive/15_USDCHF.csv_candle_classes\n",
      "using ./archive/15_USDJPY.csv_candle_classes\n",
      "using ./archive/15_GBPUSD.csv_candle_classes\n",
      "using ./archive/15_EURUSD.csv_candle_classes\n",
      "using ./archive/15_GBPJPY.csv_candle_classes\n",
      "using ./archive/15_GBPJPY.csv_candle_classes\n",
      "using ./archive/15_AUDUSD.csv_candle_classes\n",
      "using ./archive/15_EURUSD.csv_candle_classes\n",
      "using ./archive/15_EURAUD.csv_candle_classes\n",
      "using ./archive/15_EURUSD.csv_candle_classes\n",
      "1000/1000 [==============================] - 362s 362ms/step - loss: 13.4107 - mean q: 0.0641 - rewards: -0.0136 - reward sum: -163.1628 - l/s: -0.6586 - t: 334.3140\n",
      "1000/1000 [==============================] - 338s 338ms/step - loss: 15.8944 - mean q: 0.2462 - rewards: 0.0178 - reward sum: 50.5726 - l/s: -0.3660 - t: 405.9299\n",
      " 434/1000 [============>.................] - ETA: 3:19 - loss: 16.6399 - mean q: 0.2797 - rewards: -0.0978 - reward sum: -458.7071 - l/s: 0.0430 - t: 354.2943"
     ]
    }
   ],
   "source": [
    "x = [environment() for _ in range(12)]\n",
    "print(\"training...\")\n",
    "n = 100000000\n",
    "agent.train(num_steps = n, envs = x, warmup = 0, log_interval = 1000, train_steps_per_step=1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d8a6ad-dd1d-4472-9721-f85511ee38b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b6bd6-0a74-44fe-a331-16639823e158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03842687-f18d-436b-b265-fc5d7cc0bad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c3d747-2a71-4130-9e9c-f23d80050017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def plot_candles(candles, name):\n",
    "#    def scale_p(p):\n",
    "#        return (p - max_l) / hlrange * h\n",
    "#    \n",
    "#    w = 300\n",
    "#    h = 200\n",
    "#    canvas = np.zeros((h,w,3), np.uint8) \n",
    "#    l = dlen\n",
    "#    single_candle_w = w / l * 0.95\n",
    "#    max_h = 0\n",
    "#    max_l = 1000000\n",
    "#    for i in candles:\n",
    "#        if i.h > max_h:\n",
    "#            max_h = i.h\n",
    "#        if i.l < max_l:\n",
    "#            max_l = i.l\n",
    "#    hlrange = max_h - max_l\n",
    "#    \n",
    "#    for i in range(len(candles)):  \n",
    "#        color = (0,200,0) if candles[i].c > candles[i].o else (0,0,200)\n",
    "#        cv2.rectangle(canvas, (int(i*single_candle_w),int(scale_p(candles[i].o))), (int((i+1)*single_candle_w),int(scale_p(candles[i].c))), color, -1)\n",
    "#        cv2.line(canvas, (int((i+0.5)*single_candle_w),int(scale_p(candles[i].h))), (int((i+0.5)*single_candle_w),int(scale_p(candles[i].l))), color)\n",
    "#\n",
    "#    canvas = canvas[::-1]\n",
    "#    \n",
    "#    cv2.imshow(name, canvas)\n",
    "#    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757cfd96-e5ab-4043-8567-2aed839a655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#while True:\n",
    "#    m15,h1,h4,d1 = x.get_sample_candles()\n",
    "#    \n",
    "#    plot_candles(m15,\"m15\")\n",
    "#    plot_candles(h1, \"h1\")\n",
    "#    plot_candles(h4, \"h4\")\n",
    "#    plot_candles(d1, \"d1\")\n",
    "#    \n",
    "#    time.sleep(0.5)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf36fa-13be-49a4-98b7-0272caa927c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m15,h1,h4,d1 = x.get_sample_candles()\n",
    "#o,h,l,c,t = x.scale_candles(m15)\n",
    "#plt.plot(o)\n",
    "#plt.plot(h)\n",
    "#plt.plot(l)\n",
    "#plt.plot(c)\n",
    "#plt.plot(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f34e5-0f6f-4108-bdac-0df9958f2a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca303c83-6e5c-490e-88cf-18b5a55990ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6a4f42-a559-4681-94fb-75d00115342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hour_offset = 8 # time - hour_offset = ny local time\n",
    "#lookback = 2000\n",
    "#mt5.initialize()\n",
    "#authorized=mt5.login(25031341, password = \"!geH2e4Pi!Ka\", server = \"TickmillUK-Demo\")\n",
    "#mt5.account_info()\n",
    "#authorized\n",
    "\n",
    "#def get_prices(symbol, tf):\n",
    "#    t = int(time.time()) + 60*60*24\n",
    "#\n",
    "#    prices = mt5.copy_rates_from(symbol, tf, t, lookback)\n",
    "#    \n",
    "#    candles = []\n",
    "#    for t,o,h,l,c,_,_,_ in prices:\n",
    "#        t = datetime.fromtimestamp(int(t)) - timedelta (hours=hour_offset)\n",
    "#        x = candle_class()\n",
    "#        x.h=h\n",
    "#        x.l=l\n",
    "#        x.o=o\n",
    "#        x.c=c\n",
    "#        x.t=t\n",
    "#        candles.append(x)\n",
    "#    \n",
    "#    \n",
    "#    return candles"
   ]
  }
 ],
 "metadata": {
  "autoscrollcelloutput": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
