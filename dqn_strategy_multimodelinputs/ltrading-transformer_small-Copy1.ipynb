{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30e6f3-94f2-4fcf-9793-821d75d1f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd    \n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "name = \"dqn_trading_transformer_test\"\n",
    "#resume = True\n",
    "resume = False\n",
    "\n",
    "warmup_parallel = 2\n",
    "train_parallel = 2\n",
    "warmup_steps = 10\n",
    "\n",
    "lr = 0.001\n",
    "memory_size = 100\n",
    "gamma = 0.95\n",
    "exploration = 0.02\n",
    "target_model_sync = 5000\n",
    "batch_size = 4\n",
    "\n",
    "dlen = 120\n",
    "pos_size = 0.02 * 100000\n",
    "comm = 15/100000\n",
    "res_high = 100\n",
    "\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"num_replicas:\", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1857a-99cd-4633-a6fb-0616a475f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "    print(\"created ./logs\")\n",
    "\n",
    "def Load(file):\n",
    "    f = open(file, \"rb\")\n",
    "    obj = pickle.load(f)\n",
    "    f.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72913f11-cf58-41b8-bcf5-34293e18b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class candle_class:\n",
    "    def __init__(self, o,h,l,c,t):\n",
    "        self.o=o\n",
    "        self.h=h\n",
    "        self.l=l\n",
    "        self.c=c\n",
    "        self.t=t\n",
    "\n",
    "class environment:\n",
    "    def __init__(self):\n",
    "        self.data_dir = \"../archive\"\n",
    "        #print(self.files)\n",
    "        #self.reset()\n",
    "\n",
    "    def reset(self, first = False):\n",
    "        self.files = [self.data_dir+\"/\"+x for x in os.listdir(self.data_dir) if \"candle_classes\" in x]\n",
    "        p = random.choice(self.files)\n",
    "        print(\"using\",p)\n",
    "        self.candles = Load(p)\n",
    "        #print(self.candles)\n",
    "        \n",
    "        \n",
    "        self.current_index = 0\n",
    "        if first:\n",
    "            self.current_index = random.randint(0,len(self.candles)-50000)\n",
    "            \n",
    "        self.d1_candles = deque(maxlen = dlen)\n",
    "        self.h4_candles = deque(maxlen = dlen)\n",
    "        self.h1_candles = deque(maxlen = dlen)\n",
    "        self.m15_candles = deque(maxlen = dlen)\n",
    "        \n",
    "        self.position = 0\n",
    "        self.entry_price = 0\n",
    "        self.equity = 0\n",
    "        self.current_equity = 0\n",
    "        self.balance = 0\n",
    "        \n",
    "            \n",
    "        self.get_sample_candles()\n",
    "        return [self.scale_candles(self.m15_candles), self.scale_candles(self.h1_candles), self.scale_candles(self.h4_candles), self.scale_candles(self.d1_candles), self.position]\n",
    "            \n",
    "    def close(self):\n",
    "        if self.position !=0:\n",
    "            self.balance = self.equity\n",
    "            self.position = 0\n",
    "        \n",
    "    def step(self, action) :\n",
    "        last_equity = self.equity\n",
    "        reset_entry_price = False\n",
    "        if action == 1: # long\n",
    "            if self.position != 1:\n",
    "                self.close()\n",
    "                self.position = 1\n",
    "                self.balance -= pos_size * comm\n",
    "                reset_entry_price = True\n",
    "                \n",
    "        elif action == 0: # short\n",
    "            if self.position != -1:\n",
    "                self.close()\n",
    "                self.position = -1\n",
    "                self.balance -= pos_size * comm\n",
    "                reset_entry_price = True\n",
    "        else:\n",
    "            print(\"no action error:\", action)\n",
    "        \n",
    "        if self.get_sample_candles() == -1:\n",
    "            print(\"error\")\n",
    "            return -1\n",
    "            \n",
    "        current_close = self.m15_candles[-1].c\n",
    "        if reset_entry_price: self.entry_price = self.m15_candles[-1].o\n",
    "        \n",
    "        percent_change = (current_close - self.entry_price) / self.entry_price\n",
    "\n",
    "        self.equity = self.balance + percent_change * pos_size * self.position\n",
    "        \n",
    "        reward = self.equity - last_equity\n",
    "        next_observation = [self.scale_candles(self.m15_candles), self.scale_candles(self.h1_candles), self.scale_candles(self.h4_candles), self.scale_candles(self.d1_candles), self.position]\n",
    "            \n",
    "        return next_observation, reward, len(self.candles) == self.current_index\n",
    "        \n",
    "        \n",
    "    def get_sample_candles(self):\n",
    "        if len(self.candles) == self.current_index:\n",
    "            return -1\n",
    "        while True:\n",
    "            # return dlen candles of d1, h4, h1 and m15\n",
    "            current_candle = self.candles[self.current_index]\n",
    "            current_hour = int(current_candle.t.split(\":\")[0])\n",
    "            current_closing_minute = int(current_candle.t.split(\":\")[1])\n",
    "\n",
    "            # m15 candles:\n",
    "            open_minute = int(current_closing_minute / 15) * 15 # candle saved the last minute but opening minute is better to use\n",
    "            self.m15_candles.append(candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour) +\":\"+str(open_minute)))\n",
    "\n",
    "            # h1 candles:\n",
    "            if  open_minute == 0: # a new hour candle started\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h1_candles) > 0:\n",
    "                    self.h1_candles[-1].c = current_candle.c\n",
    "                    self.h1_candles[-1].h = max(current_candle.h, self.h1_candles[-1].h)\n",
    "                    self.h1_candles[-1].l = min(current_candle.l, self.h1_candles[-1].l)\n",
    "\n",
    "            # h4 candles:\n",
    "            # create a new h4 candle when hour is 17, 21, 1, 5, 9, 13\n",
    "            if  (current_hour == 17 or current_hour == 21 or current_hour == 1 or current_hour == 5 or current_hour == 9 or current_hour == 13) and open_minute == 0:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.h4_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.h4_candles) > 0:\n",
    "                    self.h4_candles[-1].c = current_candle.c\n",
    "                    self.h4_candles[-1].h = max(current_candle.h, self.h4_candles[-1].h)\n",
    "                    self.h4_candles[-1].l = min(current_candle.l, self.h4_candles[-1].l)\n",
    "\n",
    "            # d1 candles:\n",
    "            # create a new d1 candle when hour is 17\n",
    "            if  current_hour == 17 and open_minute == 0:\n",
    "                new_candle = candle_class(current_candle.o, current_candle.h, current_candle.l, current_candle.c, str(current_hour)+\":00\")\n",
    "                self.d1_candles.append(new_candle)\n",
    "            else:\n",
    "                if len(self.d1_candles) > 0:\n",
    "                    self.d1_candles[-1].c = current_candle.c\n",
    "                    self.d1_candles[-1].h = max(current_candle.h, self.d1_candles[-1].h)\n",
    "                    self.d1_candles[-1].l = min(current_candle.l, self.d1_candles[-1].l)\n",
    "\n",
    "            self.current_index+=1    \n",
    "            if len(self.d1_candles) == dlen:\n",
    "                break\n",
    "\n",
    "        return self.m15_candles,  self.h1_candles, self.h4_candles, self.d1_candles\n",
    "    \n",
    "    \n",
    "    def scale_candles(self, candles):\n",
    "        def scale_p(p):\n",
    "            return int((p - max_l) / hlrange * (res_high))\n",
    "        max_h = 0\n",
    "        max_l = 1000000\n",
    "        for i in candles:\n",
    "            if i.h > max_h:\n",
    "                max_h = i.h\n",
    "            if i.l < max_l:\n",
    "                max_l = i.l\n",
    "        hlrange = max_h - max_l\n",
    "        \n",
    "        \n",
    "        def scale_time(t):\n",
    "            hour = int(t.split(\":\")[0])\n",
    "            minute = int(t.split(\":\")[1])\n",
    "            total = hour * 60 + minute\n",
    "            max_t = 24*60\n",
    "            scaled = total / max_t\n",
    "            return scaled\n",
    "            \n",
    "        \n",
    "        \n",
    "        image = []\n",
    "        for i in candles:\n",
    "            clm = np.zeros(shape = (res_high+1))\n",
    "            color = 1 if i.o<i.c else -1\n",
    "            high_scaled = scale_p(i.h)\n",
    "            low_scaled = scale_p(i.l)\n",
    "            clm[low_scaled:high_scaled] = 0.5 * color\n",
    "            open_scaled = scale_p(i.o)\n",
    "            close_scaled = scale_p(i.c)\n",
    "            if color == 1:\n",
    "                clm[open_scaled:close_scaled+1] = color\n",
    "            if color == -1:\n",
    "                clm[close_scaled:open_scaled+1] = color\n",
    "                \n",
    "            c_time = scale_time(i.t)\n",
    "            clm[-1] = c_time\n",
    "            image.append(clm)\n",
    "        \n",
    "        current_close = candles[-1].c\n",
    "        scaled_close = scale_p(current_close)\n",
    "        clm = np.zeros(shape = (res_high+1))\n",
    "        clm[scaled_close] = 1\n",
    "        image.append(clm)\n",
    "        \n",
    "        return np.array(image).T\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e45129f-c84c-4ca0-b6ea-94cbf198af0d",
   "metadata": {},
   "source": [
    "x = environment()\n",
    "m15,h1,h4,d1,pos = x.reset(True)\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(m15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46640191-4de7-4379-b28a-b26c1567736c",
   "metadata": {},
   "source": [
    "#x = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "x = tf.convert_to_tensor(np.array(m15).reshape(1,res_high+1, dlen+1))\n",
    "#x1 = image\n",
    "#x2 = time\n",
    "x1 = x[::, :-1, :-1]\n",
    "x2 = x[::,-1,:-1]\n",
    "current_pos = x[::,::, -1]\n",
    "print(x.shape)\n",
    "print(x1.shape)\n",
    "print(x2.shape)\n",
    "print(current_pos.shape)\n",
    "\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(x1.numpy()[0])\n",
    "plt.show()\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(x2.numpy())\n",
    "plt.show()\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(current_pos.numpy())\n",
    "plt.show()\n",
    "plt.figure(figsize =(15,10))\n",
    "plt.imshow(x.numpy()[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d93b96-6791-4063-8051-069a9f830501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.05, **kwargs):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(TransformerBlock, self).get_config()\n",
    "        base_config['embed_dim'] = self.embed_dim\n",
    "        base_config['num_heads'] = self.num_heads\n",
    "        base_config['ff_dim'] = self.ff_dim\n",
    "        base_config['rate'] = self.rate\n",
    "        return base_config\n",
    "    \n",
    "    \n",
    "    \n",
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim, **kwargs):\n",
    "        self.maxlen = maxlen\n",
    "        self.embed_dim = embed_dim\n",
    "        super(PositionEmbedding, self).__init__(**kwargs)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = self.maxlen\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(PositionEmbedding, self).get_config()\n",
    "        base_config['maxlen'] = self.maxlen\n",
    "        base_config['embed_dim'] = self.embed_dim\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701228a-b593-43e5-a4fa-ddf2063b9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def proc_chart(x):\n",
    "    #x1 = image\n",
    "    #x2 = time\n",
    "    x1 = x[::, :-1, :-1]\n",
    "    x2 = x[::,-1,:-1]\n",
    "    current_pos = x[::,::, -1]\n",
    "\n",
    "    x1 = tf.keras.layers.Reshape((res_high, dlen, 1))(x1)\n",
    "    \n",
    "    x5 = tf.keras.layers.Conv2D(16, 3,activation=\"relu\", padding=\"same\")(x1)\n",
    "    x1 = tf.keras.layers.Concatenate()([x1,x5])\n",
    "    x5 = tf.keras.layers.Conv2D(16, 3,activation=\"relu\", padding=\"same\")(x1)\n",
    "    x1 = tf.keras.layers.Concatenate()([x1,x5])\n",
    "    #x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    x1 = tf.keras.layers.Dense(12)(x1)\n",
    "    \n",
    "    x1 = tf.transpose(x1,perm=[0, 2, 1, 3])\n",
    "    x1 = tf.keras.layers.Reshape((dlen, res_high*x1.shape[-1]))(x1)\n",
    "    x2 = tf.keras.layers.Reshape((dlen, 1))(x2)\n",
    "    x1 = tf.keras.layers.Concatenate()([x1,x2])\n",
    "    \n",
    "    x1 = tf.keras.layers.Dense(256)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(256)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(96)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    \n",
    "    \n",
    "    x1 = PositionEmbedding(dlen, x1.shape[-1])(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "    x1 = TransformerBlock(x1.shape[-1], 8, 256)(x1)\n",
    "\n",
    "    x1 = tf.keras.layers.Dense(256)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(32)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(16)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Concatenate()([x1,current_pos])\n",
    "    x1 = tf.keras.layers.Dense(1024)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(256)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.LayerNormalization()(x1)\n",
    "    return x1\n",
    "    \n",
    "with strategy.scope():\n",
    "    input_m15 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_h4 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    input_d1 = tf.keras.layers.Input(shape = (res_high+1, dlen+1))\n",
    "    \n",
    "    x1 = proc_chart(input_m15)\n",
    "    x2 = proc_chart(input_h1)\n",
    "    x3 = proc_chart(input_h4)\n",
    "    x4 = proc_chart(input_d1)\n",
    "    \n",
    "    input_net_position = tf.keras.layers.Input(shape = (1))\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Concatenate()([x1,x2,x3,x4,input_net_position])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dense(1024)(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(2, activation = \"linear\", use_bias=False, dtype=\"float32\")(x)\n",
    "    model = tf.keras.Model([input_m15,input_h1,input_h4, input_d1, input_net_position], outputs)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835645d-95a9-484d-b4d3-04ce14fb2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db0d3e-7df8-4a56-b06c-ea9aeb7a1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "\n",
    "log_folder = \"./\"\n",
    "\n",
    "agent = DQNAgent(\n",
    "    model = model, \n",
    "    strategy = strategy,\n",
    "    n_actions = 2, \n",
    "    memory_size = memory_size, \n",
    "    gamma=gamma,\n",
    "    optimizer = opt,\n",
    "    batch_size = batch_size, \n",
    "    target_model_sync = target_model_sync,\n",
    "    exploration = exploration,\n",
    "    name=log_folder+name+\".h5\")\n",
    "\n",
    "if resume:\n",
    "\tprint(\"loading weights...\")\n",
    "\tagent.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411125ec-439f-4de3-bcc3-4e0abf9d3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [environment() for _ in range(warmup_parallel)]\n",
    "print(\"warmup...\")\n",
    "n = warmup_steps\n",
    "agent.train(num_steps = n, envs = x, warmup = n, log_interval = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb27070-100e-4c75-b51d-3d30d7132ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agent.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a81a7b-54d5-4796-b801-0e98ffee8890",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [environment() for _ in range(train_parallel)]\n",
    "print(\"training...\")\n",
    "n = 1000000000\n",
    "agent.train(num_steps = n, envs = x, warmup = 0, log_interval = 1000)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99668af5-9022-416d-9a39-46886ff14463",
   "metadata": {},
   "outputs": [],
   "source": [
    "rew = [i[2] for i in agent.memory]\n",
    "sorted(rew)[0:10], sorted(rew)[-10:][::-1], \" - \", np.mean([abs(i) for i in rew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a23302-fdb4-45f5-a315-6cc784c94461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ba604-8d37-4c7c-957c-74e333f91a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8225cbed-9425-4cf1-af1b-9b23242d418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.uniform(shape=[2], minval=0, maxval=2, dtype=tf.int32).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357d921-1a96-4ba9-b6d5-5d149087d4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9db84-114f-429a-977f-126d8dc2d3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "autoscrollcelloutput": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
